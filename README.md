# 20201 Foundations of Deep Learning

## Graduate Programme, Faculty of Engineering


## Schedule
                        ------------- CLASSROOMS -------------
                        TUE                       THU
        weekstart week# 18-210                    20-343
        ------------------------------------------------------
        10/feb    1     IntroML1                  IntroML2     
        17/feb    2     U1.Intro.NN               Labs      
        24/feb    3     U2.NN.Archs.Train.Reg     Labs
        02/mar    4     U2.NN.Init.Batch.Vanish   Labs 
        09/mar    5     U3.Tensorflow             Labs           15/mar deadline U2.Labs            
        16/mar    6     U4.CNN.ConvOp.Archs       Labs 
        23/mar    6     U4.CNN.Classf.Semg.Detect Labs           30/mar deadline U3 Labs 
        --------------------- VACACIONES --------------------------------
        13/abr    8     U4.CNN.Transfer.GANs      Labs           19/abr deadline U4
        20/abr    9     U4.Proyecto               U4.Proyecto    
        27/abr   10     U4.Proyecto               U4.Proyecto    04/may deadline U4.Proyecto
        04/may   11     U5.RNN.SeqModls.Bprop     Labs           30/abr presentation selected projects
        11/may   12     U5.RNN.LSTM.Archs.S2Seq   Labs          
        18/may   13     U5.RNN.CNN-LSTM .         Labs           24/may deadline U5.Labs
        25/may   14     U5.Proyecto               U5.Proyecto    28/may deadline U5.Proyecto
    
## Evaluación
 
     20% Lab1 + Lab 2
     15% Lab 3
     15% Lab 4
     25% U3.Proyecto
     25% U4.Proyecto
     
## Proyectos

Para el proyecto U3 (redes convolucionales) y U4 (redes recurrentes) tendrás que:

- escoger un dataset, de un tema de tu interés, de tu investigación, etc.
- plantear una tarea de aprendizaje junto con una métrica de evaluación (p.ej. clasificación, detección, etc.)
- plantear una estrategia de resolución (preprocesado, arquitectura de red, trasnfer learning, data augmentation, feature learning, etc.)
- implementar el flujo de trabajo experimental

### Entrega

Tu entrega habrá de ser **un repositorio github** con uno o varios notebooks donde proveas evidencia del trabajo realizado, incluyendo experimentos pruebas, etc.

**Para realizar tu entrega**, crea un documento llamado `U3.Proyecto` o `U4.Proyecto` en el Google drive compartido, que contenga el enlace a tu repositorio github. Si llamas distinto a este documento **no será tenido en cuenta**.

### Criterios de evaluación

- **25% Reproducibilidad**: Tus notebooks han de ser 100% ejecutables sin errores, desde la descarga de datos hasta la obtención de tus resultados. Si lo consideras necesario crea un fichero descargable con tus datos y publícalo en algún lado como están en los notebooks del curso. **No incluyas los datos en el repositorio**.
- **25% Claridad**: Explica bien tu tarea (en los mismos notebooks), la métrica de evaluación que ests usando y el ciclo experimental que hiciste (probé tales arquitecturas de red, el modelo final tiene tal arquitectura porque las anteriores sufrían de overfitting, etc.) 
- **25% Repositorio**: Tu repositorio ha de estar ordenado, con una estructura clara y con un README.md que indique qué notebooks ejecutar con tu resultado final, qué notebooks contienen los experimentos previos que hiciste, etc.
- **25% Compleción**: Tu tarea ha de utilizar las técnicas vistas en clase y ha de demostrar un flujo experimental (prueba de varias arquitecturas, preprocesados, etc.). Igualmente has de incluir una **interpretación de tus resultados**.

### Presentación

Si se te requiere tendrás que realizar una **breve presentación** de tu proyecto, teniendo en cuenta que:

- la presentacin ha de durar **10 minutos**. Esto es un límite **estricto**. Al cabo de ese tiempo se cortará la presentación esté en el punto que esté.
- Tendrás que presentar **tres aspectos**: 1) qué tarea se resolvió, 2) qué experimentos se hicieron, 3) tus conclusiones e interpretación de los resultados.
- La calificación será **un factor entre 0.5 y 1.5**, que se multiplicará con la calificación obtenida a la entrega para obtener la calificación final.

 ## Registro y materiales
 
 - [Máquina virtual del curso](https://drive.google.com/file/d/1ybeLv2nwBfssKN0-ulbmw9o_20SpjF7W/view?usp=sharing)

## Lecturas recomendadas

- Hastie, Tibshirani, Friedman, **The Elements of Statistical Learning**, Springer-Verlag [website](https://web.stanford.edu/~hastie/ElemStatLearn/) [pdf](https://web.stanford.edu/~hastie/ElemStatLearn/printings/ESLII_print12.pdf)
- Goodfellow, Bengio, Courville, **Deep Learning**, MIT Press [website](https://www.deeplearningbook.org/) [pdf](https://github.com/janishar/mit-deep-learning-book-pdf)
- Bengio, **Learning Deep Architectures for AI**, Foundations and Trends in
Machine Learning, Vol. 2, No. 1 (2009) 1–127, [pdf](http://www.iro.umontreal.ca/~bengioy/papers/ftml_book.pdf)
