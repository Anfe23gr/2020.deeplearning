{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "U2.07 - Vanishing gradients.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZ-OGg2XUH9c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "944bf74e-e51d-4070-b3aa-007d4344a35a"
      },
      "source": [
        "!wget --no-cache -O init.py -q https://raw.githubusercontent.com/rramosp/2020.deeplearning/master/init.py\n",
        "from init import init; init(force_download=False)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "replicating local resources\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3bDeERPUH9j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6d53e961-a2fe-40e8-c3e5-f334365554f5"
      },
      "source": [
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "    print (\"setting tensorflow version in colab\")\n",
        "    %tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "setting tensorflow version in colab\n",
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt5L7QJDUH9n",
        "colab_type": "text"
      },
      "source": [
        "forward/back propagation calculations https://medium.com/@14prakash/back-propagation-is-very-simple-who-made-it-complicated-97b794c97e5c\n",
        "\n",
        "Vanishing gradient example: https://github.com/harinisuresh/VanishingGradient/blob/master/Vanishing%20Gradient%20Example.ipynb\n",
        "\n",
        "https://adventuresinmachinelearning.com/vanishing-gradient-problem-tensorflow/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tncUg_QRUH9o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "bfdff993-f6f7-4978-bccd-1c5a811a035d"
      },
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>.container { width:100% !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjHbQiWkUH9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5urbhDe8UH9u",
        "colab_type": "text"
      },
      "source": [
        "# Visualizing and understanding vanishing gradients\n",
        "\n",
        "Make sure you understand well the backpropagation algorithm. You may perform by hand the calculations as illustrated [here](https://medium.com/@14prakash/back-propagation-is-very-simple-who-made-it-complicated-97b794c97e5c) to consolidate your understanding.\n",
        "\n",
        "We will be using three activation functions. Observe under which what values each function's gradient becomes negligible (very near zero)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iz7s0-NaUH9v",
        "colab_type": "text"
      },
      "source": [
        "### sigmoid\n",
        "\n",
        "$$\\text{sigm(z)} = \\frac{1}{1-e^{-z}}$$\n",
        "\n",
        "$$\\frac{\\partial \\;\\text{sigm}}{\\partial \\; z} = \\text{sigm}(z)(1-\\text{sigm}(z))$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwCP_spVUH9w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "d257ce5a-2fc5-469d-952a-4d2a1f8caaa1"
      },
      "source": [
        "z = np.linspace(-10,10,100)\n",
        "\n",
        "sigm = lambda z: 1/(1+np.exp(-z))\n",
        "\n",
        "dsigm = lambda z: sigm(z)*(1-sigm(z))\n",
        "\n",
        "plt.plot(z, sigm(z), lw=5, label=\"sigm\")\n",
        "plt.plot(z, dsigm(z), lw=5, label=\"grad sigm\")\n",
        "plt.grid()\n",
        "plt.axvline(0, color=\"black\");\n",
        "plt.axhline(0, color=\"black\");\n",
        "plt.legend()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7effd76d1898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXSml4sT/BwEi3JUBT/sjAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyemSqtRUH9z",
        "colab_type": "text"
      },
      "source": [
        "### tanh\n",
        "\n",
        "$$\\text{tanh(z)} = \\frac{e^z - e^{-z}}{e^z-e^{-z}}$$\n",
        "\n",
        "$$\\frac{\\partial \\;\\text{tanh}}{\\partial \\; z} = 1-\\text{tanh}(z)^2$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-VIwHGJUH90",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "a3ae37a6-0503-4533-c298-58175f8ede30"
      },
      "source": [
        "z = np.linspace(-10,10,100)\n",
        "\n",
        "tanh = lambda z: (np.exp(z)-np.exp(-z))/(np.exp(z)+np.exp(-z))\n",
        "\n",
        "dtanh = lambda z: 1 - tanh(z)**2\n",
        "\n",
        "plt.plot(z, tanh(z), lw=5, label=\"tanh\")\n",
        "plt.plot(z, dtanh(z), lw=5, label=\"grad tanh\")\n",
        "plt.grid()\n",
        "plt.axvline(0, color=\"black\");\n",
        "plt.axhline(0, color=\"black\");\n",
        "plt.legend()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7effd49c3518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmH7OEoExxvRzlgiMMaafs0RgjDH93P8HY0bBD2VqdskAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1xSL7SfUH93",
        "colab_type": "text"
      },
      "source": [
        "### ReLU (Rectified Linear Unit)\n",
        "\n",
        "$$\\text{relu}(z) = \\text{z if }z<0\\;;\\;0\\text{ otherwise}$$\n",
        "\n",
        "$$\\frac{\\partial \\;\\text{relu}}{\\partial \\; z} = \\text{1 if }z<0\\;;\\;0\\text{ otherwise}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an0FW5PnUH94",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "a183b642-cf4f-4e14-a781-925e3cb6338a"
      },
      "source": [
        "z = np.linspace(-2,2,100)\n",
        "\n",
        "relu = np.vectorize(lambda z: z if z>0 else 0.)\n",
        "\n",
        "drelu = np.vectorize(lambda z: 1 if z>0 else 0.)\n",
        "\n",
        "plt.plot(z, relu(z), lw=5, label=\"relu\")\n",
        "plt.plot(z, drelu(z), lw=5, label=\"grad relu\")\n",
        "plt.grid()\n",
        "plt.axvline(0, color=\"black\");\n",
        "plt.axhline(0, color=\"black\");\n",
        "plt.legend()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7effd4950be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxU9bn48c9DFgIE2QIRAVkEVFCW\nEAUVNe7WBdqqFYq3eq9eLIrWul1bq1K1ty6tvRZcym0p9ieCu0WLCy4jVQtCwiI7EVAS0bAlECDb\n5Pn9MQN3yJlkTpJZTibP+/XKi5nv95w5zxySZ77zPec8R1QVY4wxyatNogMwxhgTW5bojTEmyVmi\nN8aYJGeJ3hhjkpwlemOMSXKpiQ4gnKysLO3Xr1+T1t2/fz8dOnSIbkBRYHE1jhfj2rBhA36/nyFD\nhiQ6FAcv7i+wuBqrOXHl5+fvVNXuYTtV1XM/o0aN0qb66KOPmrxuLFlcjePFuM4++2wdPnx4osMI\ny4v7S9XiaqzmxAUs03pyqk3dGGNMkrNEb4wxSc4SvTHGJDlPHowNp7q6mqKiIioqKhpcrlOnTqxb\nty5OUbmX6LgyMjLo3bs3aWlpCYvBGJMYLSbRFxUV0bFjR/r164eI1Lvcvn376NixYxwjcyeRcakq\nu3btoqioiP79+yckBmNMw/bsr0JjVHss4tSNiPQRkY9EZK2IrBGRn4VZRkTkjyJSKCKrRCQnpO9a\nEdkU/Lm2qYFWVFTQrVu3BpO8CU9E6NatW8RvQ8aYxCivrOGKZz/jT6sq2V9ZE/XXdzNHXwPcoapD\ngDHAzSJS90Ti7wGDgj+TgWcARKQr8AAwGjgVeEBEujQ1WEvyTWf7zhhvUlX+69VVbN6xn8Xb/Xz/\nqU8pLNkX1W1ETPSqul1VC4KP9wHrgF51FhsP/C14OudioLOI9AQuAhaq6m5V3QMsBC6O6jswxpgW\nbPZnW/nHqu2Hn28qKWfcjE/5cP13UdtGo+boRaQfMBJYUqerF7At5HlRsK2+9nCvPZnAtwGys7Px\n+XxH9Hfq1Il9+yJ/yvn9flfLxcoll1zCww8/TE5OzhHtiY4LAtNfdfdreXm5o80LvBhXaWkpfr/f\nc3GBN/cXWFyRFO7x89vPnVOqfr+f7YVr8H0bnRM4XCd6EckEXgVuU9W9Udl6CFWdCcwEyM3N1by8\nvCP6161b5+pgZjwOeh6+2qyN8wtRSkoKHTp0cMTghYPEGRkZjBw58og2n89H3X3tBV6Mq3PnzpSW\nlnouLvDm/gKLqyG7yiv5xfRP8Ic5/vrYVSMYPyLsmLhJXCV6EUkjkOTnqOprYRYpBvqEPO8dbCsG\n8uq0+5oS6CH97vlHc1Z3Zesjlzrbtm7loosuYvTo0eTn53P33Xfz7LPPUllZyXHHHcdf//pXMjMz\nj1gnMzOT8vJyAN544w0++OADZs+eHfP4jTHe5q9VfjZvBdvLnKP5n5zWN6pJHtyddSPAX4B1qvpE\nPYvNB34SPPtmDFCmqtuBd4ELRaRL8CDshcG2FmnTpk3cdNNNfPzxx/zlL3/h/fffp6CggNzcXJ54\nor5dY4wxR3ry/Y18UrjT0T6gUxvuvfTEqG/PzYj+DODfgC9EZEWw7ZfAsQCq+iywALgEKAQOAP8e\n7NstIg8BS4PrPaiqu6MXfnz17duXMWPG8NZbb7F27VrOOOMMAKqqqjjttNMSHJ0xpiX4aH0Jf/yw\n0NHepX0aN49IpW1qStS3GTHRq+onQIPn5gUrp91cT98sYFaTovOYQ+VDVZULLriAuXPnNrh86CmN\ndg67MWbb7gPc9uIKR7sIPDlhJLXfrInJdq3WTROMGTOGTz/9lMLCwKfy/v372bhxo2O57Oxs1q1b\nR21tLW+99Va8wzTGeEhljZ+bXyig7GC1o+9n5w3irMHhS8lHQ4spgXBIuAOloeJxdkv37t2ZPXs2\nEydOpLKyEoCHH36YwYMHH7HcI488wmWXXUb37t0ZNmwYVVVVMY3LGONdD765llVFZY72swZ359Zz\nB8V02y0u0SdKv379WL169eHn5557LkuXLnUsF3pu7pVXXsmVV14JeOP0SmNMYry+vIg5S752tB/T\nKYP/uXoEbdrE9sp1m7oxxpgY2vDtPn752mpHe1qK8PQ1o+jaIT3mMViiN8aYGNlXUc2U5/M5WO13\n9N132RBG9Okclzgs0RtjTAwcLla2c7+jb/yIY/i3MX3jFoslemOMiYFZn25lwRffOtoH9cjktz88\nOa4VZS3RG2NMlOV/tZvfLnAWJOuQnsIz14yifXp8z4OxRG+MMVG0s7ySm+YUUFPrrFb2yBXDGNgj\nM8xasWWJPoH69evHzp3OehduXXfddbzyyitRjMgY0xyBYmXL+W5vpaPvutP7cfnwYxIQlSX6qKup\nie5twPx+59F6Y4w3/WHhRj4t3OVozzm2M7+8JPrFytxqeRdMTevUYHdULkma5rx6DeChhx7i+eef\np3v37vTp04dRo0Zx5513kpeXx4gRI/jkk0+YOHEigwcP5uGHH6aqqopu3boxZ84c2rdvz65du5g4\ncSLFxcWcdtpp9d4IODMzkxtvvJH333+fp556inbt2nH77bdTXl5OVlYWs2fPpmfPnkes069fP5Yt\nW0ZWVhbLli3jzjvv9MSNFYxpLT5c/x0zPnIWK+vaIZ2nJuWQnpq4cbWN6F1aunQpr776KitXruTt\nt99m2bJlR/RXVVWxbNky7rjjDsaOHcvixYtZvnw5EyZM4LHHHgPg17/+NWPHjmXNmjX84Ac/4Ouv\nnVfKQaB2zujRo1m5ciWjR4/mlltu4ZVXXiE/P5//+I//4N577435+zXGuLdt9wFum1dfsbIR9OzU\nLgFR/Z+WN6JPkE8//ZTx48eTkZFBRkYGl19++RH9V1999eHHRUVFXH311Wzfvp2qqir69+8PwKJF\ni3jttcB9Wy699FK6dAl/n/SUlBSuuOIKADZs2MDq1au54IILgMBUTt3RvDEmcSqq/UyZk8/eCue0\n7c/PH8yZg2JXrMwtS/RRcqiEMcAtt9zC7bffzrhx4/D5fEybNq1Rr5WRkUFKSqAmtaoydOhQ/vWv\nfzW4TmpqKrW1tYCVRDYmnn795lpWFzvvrpp3fHemnjMwARE52dSNS2eccQZvvvkmFRUVlJeXN1h2\nuKysjF69ArcCe+655w63n3XWWbzwwgsAvP322+zZsyfido8//nh27NhxONFXV1ezZo2zZnW/fv3I\nz88H4NVXX3X/xowxTfZqfhFzP3dOwfbq3I4//Cj2xcrcijiiF5FZwGVAiaqeFKb/LmBSyOudCHQP\n3l1qK7AP8AM1qprb7IjrOVB6SKyqRJ5yyimMGzeOYcOGkZ2dzcknn0ynTuEPDE+bNo2rrrqKLl26\ncO6557JlyxYAHnjgASZOnMjQoUM5/fTTOfbYYyNuNz09nVdeeYVbb72VsrIyampquO222xg6dOgR\nyz3wwANcf/313HfffQm/6bExrcH6b/dy7xtfONrTU9rw9KQcusShWJlbbqZuZgMzgL+F61TVx4HH\nAUTkcuDndW4XeI6qNv1kcQ+58847mTZtGgcOHOCss85i1KhRAI6zW8aPH8/48eOPaNu3bx/dunXj\nvffei7idQzcUP2TEiBEsWrTIsVzojcbPPPPMsDc/McZE396KaqY8X0BFda2j7/7LhzA8TsXK3HJz\nK8FFItLP5etNBBq+v14LNnnyZNauXUtFRQXXXnstOTk5iQ7JGBNnqsrdL69iS5hiZT8Y2YtJoyN/\nU483qe9c7iMWCiT6t8JN3YQs0x4oAgYeGtGLyBZgD6DAn1R1ZgPrTwYmA2RnZ4+aN2/eEf2dOnVi\n4MDIBzb8fv/hA5le4oW4CgsLKSs7cuqrvLyczMz4X5IdiRfjuu222/D7/UyfPj3RoTh4cX9Bcsb1\nzpZq5m1w3i2uV6Zw/5h2tE1t+rx8c+I655xz8uubHo/mWTeXA5/WmbYZq6rFItIDWCgi61XVOQcB\nBD8EZgLk5uZq3XnmdevWkZmZGbHim1fv5JTouFSVjIwMRo4ceUS7z+fz5Jy+F+Pq3LkzpaWlnosL\nvLm/IPniWrp1Ny+/t9jRntk2lb/deAbHdW/eh1qs9lc0z7qZQJ1pG1UtDv5bArwOnNrUF8/IyGDX\nrl31Xk1q6qeq7Nq1i4yMjESHYkyLtWNfJTfPKcAfpljZY1cOa3aSj6WojOhFpBNwNnBNSFsHoI2q\n7gs+vhB4sKnb6N27N0VFRezYsaPB5SoqKjyZ0BIdV0ZGBr17907Y9o1pyWr8tdwyt4CSfc5iZdeP\n7c8lJ3v7IkY3p1fOBfKALBEpAh4A0gBU9dngYj8A3lPV0KMT2cDrwamWVOAFVX2nqYGmpaUdvsK0\nIT6fzzE94QVejcsYE9nvF25k8ebdjvbcvl2453snJCCixnFz1s1EF8vMJnAaZmjbZmB4UwMzxhgv\nWLj2O57xfelo79YhnRk/ziEtxfvXnXo/QmOMSZCvdx3g9pecxcraCEyfOJKjO3lvmjgcS/TGGBPG\noWJl+8IUK7vjwuM5fWBWAqJqGkv0xhgTxrT5a1jzjbNY2Xkn9GDK2cclIKKms0RvjDF1vLxsG/OW\nbnO09+7Sjic8VKzMLUv0xhgTYu03e/nVG6sd7ekpbXhm0ig6tU9LQFTNY4neGGOC9lZUc9OcfCpr\nnMXKpo0bysm9G76VqVdZojfGGAJXkN/18kq27jrg6PthTi8mntonAVFFhyV6Y4wB/vefm3l3zXeO\n9hOO7shvvn9yxDpbXmaJ3hjT6i3ZvItH39ngaM9sm8rTk3Jol+69iriNYYneGNOqleytYOrc5WGL\nlf3uqmEM8HCxMrcs0RtjWq1AsbLl7AhTrOyGsf25+CRvFytzyxK9MabVevy9DSzZEr5Y2X+1gGJl\nblmiN8a0Su+t+ZY/fbzZ0Z6Vmc5Tk1pGsTK3kuedGGOMSyUHarnj5ZWO9jYCf5w4kuyjWkaxMrei\neStBY4zxvIpqP9OXV7KvwnlR1J0XHc/px7WcYmVu2YjeGNOq3P/31Wzb50zy55/Yg5+e1bKKlbkV\nMdGLyCwRKRERZ/GHQH+eiJSJyIrgz/0hfReLyAYRKRSRe6IZuDHGNNZLS7fx0rIiR3ufru34/VUt\nr1iZW25G9LOBiyMs809VHRH8eRBARFKAp4DvAUOAiSIypDnBGmNMU635poz7/h6mWFlqyy1W5lbE\nRK+qiwDn+UeRnQoUqupmVa0C5gHjm/A6xhjTLGUHq7lpTkHYYmUPjhvKSb1aZrEyt6J1MPY0EVkJ\nfAPcqaprgF5AaEHnImB0fS8gIpOByQDZ2dn4fL4mBVJeXt7kdWPJ4mocL8ZVWlqK3+/3XFzgzf0F\n3ohLVfnj8kq+2uV39I3tlUr2/i/x+ZynWSZCrPZXNBJ9AdBXVctF5BLgDWBQY19EVWcCMwFyc3M1\nLy+vScH4fD6aum4sWVyN48W4OnfuTGlpqefiAm/uL/BGXM9+/CXLS9Y72k84uiP/e+MZnqpjE6v9\n1eyzblR1r6qWBx8vANJEJAsoBkLrevYOthljTFws3ryLx991FitrlwrPXjPKU0k+lpqd6EXkaAnW\n7xSRU4OvuQtYCgwSkf4ikg5MAOY3d3vGGONGyd4Kpr4QvljZDSe3pV9WhwRElRgRp25EZC6QB2SJ\nSBHwAJAGoKrPAlcCU0SkBjgITFBVBWpEZCrwLpACzArO3RtjTExV+2uZ+sJydpY7i5VNPmsAo9o7\n684ns4iJXlUnRuifAcyop28BsKBpoRljTNM8/u4GPt/qPFnw1H5dufui4/nkn60r0duVscaYpPLO\n6m+ZuShcsbK2zPjxSFKTqFiZW63vHRtjktaWnfu5K0yxspQ2wowfj6RHkhUrc8sSvTEmKRys8jPl\n+Xz2VdY4+u666HjGDOiWgKi8wRK9MabFU1Xu+/tq1n+7z9F3wZBsbjxrQAKi8g5L9MaYFu/Fpdt4\nJd9ZrKxvt/b87qrhBM8Ab7Us0RtjWrTVxWXcP9955nbb1DY8PSmHTu2St1iZW5bojTEtVtmBaqbM\nyacqTLGyh8afxNBjkrtYmVuW6I0xLVJtrXL7SyvYtvugo+9Hub350Sl9wqzVOlmiN8a0SM98/CUf\nrC9xtA/peRQPjj8pARF5lyV6Y0yL89mXO/n9e85iZR0zUnnmmhwy0lpHsTK3LNEbY1qUb8squHXu\ncsLUKuP3Vw2nb7fWU6zMLUv0xpgWI1CsrICd5VWOvhvPHsCFQ49OQFTeZ4neGNNiPPr2epZ9tcfR\nPrp/V+668PgERNQyWKI3xrQI76zezp8/2eJo79GxLdNbabEyt2zPGGM8b/OOcu58eZWjPaWNMH3i\nSHp0bJ3FytyKmOhFZJaIlIjI6nr6J4nIKhH5QkQ+E5HhIX1bg+0rRGRZNAM3xrQOB6v83DSngPIw\nxcr+6+LjGd2Ki5W55WZEPxu4uIH+LcDZqnoy8BDBG3yHOEdVR6hqbtNCNMa0VqrKvW98EbZY2UVD\ns/nPM1t3sTK33NxhapGI9Gug/7OQp4sJ3ATcGGOabe7n23itoNjR3q9bex63YmWuSeD2rhEWCiT6\nt1S1wcvNRORO4ARVvSH4fAuwB1DgT6pad7Qfuu5kYDJAdnb2qHnz5rl8C0cqLy8nMzOzSevGksXV\nOF6M67bbbsPv9zN9+vREh+Lgxf0FzYtra5mfhxdXUFMnRaW1gfvGZHDsUU2/KCoZ99c555yTX9/M\nScQRvVsicg5wPTA2pHmsqhaLSA9goYisV9VF4dYPfgjMBMjNzdW8vLwmxeHz+WjqurFkcTWOF+Pq\n3LkzpaWlnosLvLm/oOlxlR6o4lfTP3EkeYD//uEwrsptXh2bZNtfkUTlrBsRGQb8GRivqrsOtatq\ncfDfEuB14NRobM8Yk7wCxcpWUrTHWaxswil9mp3kW6NmJ3oRORZ4Dfg3Vd0Y0t5BRDoeegxcCIQ9\nc8cYYw552lfIh2GKlQ095iimjRuagIhavohTNyIyF8gDskSkCHgASANQ1WeB+4FuwNPBAyM1wXmi\nbOD1YFsq8IKqvhOD92CMSRKfFu7kiYUbHe1HZaTyzKRRVqysidycdTMxQv8NwA1h2jcDw51rGGOM\nU0PFyp740QiO7dY+/kElCbsy1hiTcNX+Wm5+oYBd+53FyqbkHcf5Q7ITEFXysERvjEm43y5YT36Y\nYmWnDejGHRcMTkBEycUSvTEmof6xajuzPg1frOyPE61YWTTYHjTGJMyXO8q5+5WVjvaUNsKMH+fQ\nvWPbBESVfCzRG2MS4kBVDVOez2d/ld/R94vvncCp/bsmIKrkZIneGBN3qsq9r69m43fljr7vnXQ0\n14/tn4CokpclemNM3M1Z8jWvL3cWK+uf1YHHrhxmxcqizBK9MSauVhWV8uCbax3tGWlteHpSDh0z\n0hIQVXKzRG+MiZs9+6uY8nwBVf5aR99vvn8yJ/Y8KgFRJT9L9MaYuKitVX7+0gqKS53FyiaeeixX\njLJbWcSKJXpjTFzM+KgQ34YdjvaTeh3FA5cPSUBErYclemNMzP1z0w7+8L6zWFmndmlWrCwOLNEb\nY2Lqm9KD/GzeCsLdzO4PVw+nT1crVhZrluiNMTFTU6tMfaGA3WGKlU09ZyDnnmDFyuIharcSNMaY\nul7cUEXB1wcc7WcM7MbPrVhZ3NiI3hgTE2+u/IaFX9U42o8+KoMnJ4wkpY1dFBUvrkb0IjILuAwo\nUdWTwvQL8CRwCXAAuE5VC4J91wK/Ci76sKo+F43AjUmENrVVkP8c1FQmOpQj9CraBEucBzsTZUd5\nJas+/pKfpBx5vnyKCP8+sh9Za75MUGQBXttfhxyOq9sAGHh+1F7X7dTNbGAG8Ld6+r8HDAr+jAae\nAUaLSFcCtx7MBRTIF5H5quosPG2M1+3fyVF7N8KbtyY6EodBAIWJjuL/dAfubUP4OYMlcQ4mDK/t\nr0MOxzX0h1FN9K6mblR1EbC7gUXGA3/TgMVAZxHpCVwELFTV3cHkvhC4uLlBG5MQpV8lOgJjmiRa\nB2N7AdtCnhcF2+prdxCRycBkgOzsbHw+X5MCKS8vb/K6sWRxNY7n4tJaqHZe0WlMLJSUlLA2ir//\nnjnrRlVnAjMBcnNzNS8vr0mv4/P5aOq6sWRxNY7n4rIkb+KoR48e9Iji73+0En0x0Cfkee9gWzGQ\nV6fdF6VtGhM/NRXh20/5z/jGUY/i4mJ69Qr7ZTkuKmr8vLVyO/urnGfZnDmoOwOyOiQgqvolen/V\n53BcPYdH9XWjlejnA1NFZB6Bg7FlqrpdRN4F/ltEugSXuxD4RZS2aUz8hDvLpkMPuPR38Y8ljE0+\nH70S9A3IX6tMnr2URQecdWzO7ZPKtddelICoGpbI/dWQWMXl9vTKuQRG5lkiUkTgTJo0AFV9FlhA\n4NTKQgKnV/57sG+3iDwELA2+1IOq2tBBXWO8KdyIPjUj/nF40PQPN7FoozPJD+/diYknVicgIlOX\nq0SvqhMj9Ctwcz19s4BZjQ/NGA8JN6JPtRtXL9q4gyc/2ORo79w+jacm5VC48vMERGXqsitjjXHD\nRvQOxaUH+dm85Y5iZSLwh6tH0LuLFSvzCkv0xrhhI/ojVNXUcvOcAvYccE7NTD1nIOcc3yMBUZn6\nWKI3xg0b0R/hN/9Yy4ptpY72sQOzuO18K1bmNZbojXHDRvSHzV/5Dc/9y3mVcM9OGTw5YYQVK/Mg\nS/TGuGEjegA2fbePe15d5WhPbSPM+HEO3TJb54ef11miN8YNG9Gzv7KGKXMKOFDld/Tde+mJjOrb\nJcxaxgss0RvjRisf0asq97z2BYUl5Y6+S4f15LrT+8U/KOOaJXpj3Aib6FvPiP5v//qKN1d+42g/\nrnsHHr1iGIFbUhivskRvjBthp25ax4i+4Os9PPyPtY72dmkpPHPNKDLbeqY2oqmHJXpj3GilI/rd\n+6u4eU4B1X519D1yxckMzu6YgKhMY1miN8aNVjii99cqP5u3nO1lzg+5n5zWl/EjvFf90YRnid4Y\nN1rhiP7JDzbxz007He3D+3Tm3ktPTEBEpqks0RvjRisb0fs2lDD9w/DFyp6elEPb1JQERGWayhK9\nMW60ohF90Z4D3PbiirDFyp6cMJJendslJjDTZJbojXGjlVwwVVnj5+Y5BZSGKVZ267mDOHtw9wRE\nZZrLEr0xbrSSC6YefmsdK4vKHO1nDsri1vMGJSAiEw2uEr2IXCwiG0SkUETuCdP/BxFZEfzZKCKl\nIX3+kL750QzemLhpBSP6N5YX8/8WO4uVHdMpgycnjLRiZS1YxCsdRCQFeAq4ACgClorIfFU9fAWF\nqv48ZPlbgJEhL3FQVUdEL2RjEiDJR/Qbv9vHL177wtGeliI8NSmHrh3SExCViRY3I/pTgUJV3ayq\nVcA8YHwDy08E5kYjOGM8I4lH9OWVNfz0+XwOVjuLlf3q0iGMPNaKlbV0bq5d7gVsC3leBIwOt6CI\n9AX6Ax+GNGeIyDKgBnhEVd+oZ93JwGSA7OxsfD6fi9CcysvLm7xuLFlcjeO1uHJ2lzjaClatZe9X\ntQmIxqmp+0tVeXplJZt3OJP8mJ4pHFu5BZ9va9zjirXWFle0i1RMAF5R1dDfmr6qWiwiA4APReQL\nVf2y7oqqOhOYCZCbm6t5eXlNCsDn89HUdWPJ4mocz8W1zjlNk3PqadBzeAKCcWrq/vrrp1tY+q2z\njs3AHpn85adn0KGZdWw89/8Y1NricjN1Uwz0CXneO9gWzgTqTNuoanHw382AjyPn741pGZJwjj7/\nqz385h/rHO3t01N49pqcZid54x1uEv1SYJCI9BeRdALJ3HH2jIicAHQB/hXS1kVE2gYfZwFnAM7h\ngzFel2Rz9DvLK7l5TgE1tc5iZY9eMYyBPaxYWTKJ+JGtqjUiMhV4F0gBZqnqGhF5EFimqoeS/gRg\nnuoR19OdCPxJRGoJfKg8Enq2jjEtRhKN6A8VK/t2r/M9XXd6Py4ffkwCojKx5Oq7maouABbUabu/\nzvNpYdb7DDi5GfEZ4w1JNKL/n/c38mnhLkf7iD6d+eUlVqwsGdmVsca4kSQj+o/WlzD9w0JHe9cO\n6Tw9KYf0VEsJycj+V42JRBX8YUb0KS1rRL9td6BYWV2BYmUjOMaKlSUtS/TGRBJu2iYlHdq0nD+f\nyho/N79QQNlBZ7Gy284bzJmDrFhZMms5v6nGJEoSTNs8+OZaVoUpVnb24O7ccu7ABERk4skSvTGR\ntPADsa8VFDFnydeO9l6d2/E/V4+gjRUrS3qW6I2JpAWP6Nd/u5dfvl5/sbIuVqysVbBEb0wkLXRE\nv6+iminPF1BR7azHc/9lQxjRp3MCojKJYInemEha4IheVbnn1S/YsnO/o2/8iGO4ZkzfBERlEsUS\nvTGRtMAR/axPt/KPL7Y72gf1yOS3PzwZEZuXb00s0RsTSQsb0S/bupvfLnAWK+uQnsIz14yifboV\nK2ttLNEbE0kLGtHvLK/k5hfqKVZ25TAG9shMQFQm0SzRGxNJCxnR+2uVW+cu57u9zg+m607vx2XD\nrFhZa2WJ3phIwiZ6743on1i4gc++dBYryznWipW1djZZZ0wkYaduvDWiX1FSw1MFjhu30bVDOk9Z\nsbJWz/73jYnE4yP6bbsPMHOV88NIBP44YSQ9O1mxstbOVaIXkYtFZIOIFIrIPWH6rxORHSKyIvhz\nQ0jftSKyKfhzbTSDNyYuPDyir6j2M2VOPgdqnH23nz+YsYOy4h+U8ZyIUzcikgI8BVwAFAFLRWR+\nmDtFvaiqU+us2xV4AMgFFMgPrrsnKtEbEw/hRvQp3igd8Os317K6eK+j/Zzju3PzOVaszAS4GdGf\nChSq6mZVrQLmAeNdvv5FwEJV3R1M7guBi5sWqjEJ4tER/Sv5Rcz9PHyxsj9YsTITws3B2F7AtpDn\nRcDoMMtdISJnARuBn6vqtnrW7RVuIyIyGZgMkJ2djc/ncxGaU3l5eZPXjSWLq3G8FNeAzRs5tk7b\n5m3f8HUC4/t6r5+HFju/aaQK3HCisuLzzxIQlZOX/h9Dtba4onXWzZvAXFWtFJEbgeeAcxvzAqo6\nE5gJkJubq3l5eU0KxOfz0Y04lA8AAA8PSURBVNR1Y8niahxPxXXwnSOHK8CAQScy4PS8hISzt6Ka\nadM/IUytMqaNP8lTdWw89f8YorXF5WbqphjoE/K8d7DtMFXdpaqHvt/+GRjldl1jPM9DZ92oKne+\ntJKtuw44+n44sheTRtf97mGMu0S/FBgkIv1FJB2YAMwPXUBEeoY8HQccKrTxLnChiHQRkS7AhcE2\nY1oOD83R/+8/N/Pe2u8c7b0zhd/8wIqVmfAiTt2oao2ITCWQoFOAWaq6RkQeBJap6nzgVhEZB9QA\nu4HrguvuFpGHCHxYADyoqrtj8D6MiZ1wNwZPQKJfsnkXj76zwdGe2TaVqSPTaJeeEveYTMvgao5e\nVRcAC+q03R/y+BfAL+pZdxYwqxkxGpNYHihqVrKvgqlzl+MPU6zssSuH0X6X8wPAmEPsylhjIklw\nUbMafy23vLCcHfucHzjXj+3PJSf3DLOWMf/HEr0xkSR4RP+79zayZItzxjO3bxfu+d4JcYvDtFyW\n6I2JJIEj+oVrv+PZj53FyrIy05nx4xzSUuxP2ERmvyXGRJKg0yu/2rWf219a4WhvEyxWdnSnxF+d\na1oGS/TGRJKA0ysrqv1Meb6AfRXOamV3XHg8pw+0YmXGPUv0xkSSgBH9A39fw9rtzmJl553Qgyln\nHxfTbZvkY4nemEjiPKJ/adk2Xly2zdHeu0s7nviRFSszjWeJ3phI4jiiX/NNGfe9sdrRnp7ahmcm\njaJT+7SYbNckN0v0xkQSpxF92cFqbppTQGWNs1rZr8cN5eTenaK+TdM6WKI3piGqcRnRqyp3vbyS\nr8IUK7sipzcTTukTZi1j3LFEb0xD/FXOtjZp0Ca6dWVmLgpfrOyEozvy8PdPsmJlplks0RvTkDhc\nLLVk8y4ee9dZq6Zj21SeuWaUFSszzWaJ3piGxLj8Qcne+ouVPX7VMPpndYjatkzrZYnemIbEcERf\n469l6tzwxcr+88z+XHySFSsz0WGJ3piGxHBE//i7G/g8TLGyU/p14e6LrViZiR5L9MY0JEYj+nfX\nfMufFm12tGdltrViZSbqXP02icjFIrJBRApF5J4w/beLyFoRWSUiH4hI35A+v4isCP7Mr7uuMZ4W\ngxH91p37ufOllY72NgLTJ44k+ygrVmaiK+IdpkQkBXgKuAAoApaKyHxVXRuy2HIgV1UPiMgU4DHg\n6mDfQVUdEeW4jYmPKI/oK6r9TJlTwL5KZ7Gyuy46gdOO69bk1zamPm5G9KcChaq6WVWrgHnA+NAF\nVPUjVT10pcdioHd0wzQmQcIm+vQmv9x9b6xmXZhiZeefmM1Pzx7Q5Nc1piFu7hnbCwitsFQEjG5g\n+euBt0OeZ4jIMgI3Dn9EVd8It5KITAYmA2RnZ+Pz+VyE5lReXt7kdWPJ4mocr8TVbWc+J9dp21m2\nn9VNiO3jompeXu28AKt7O+EHx+zj448/blqQeGd/1WVxNU6s4nJ1c3C3ROQaIBc4O6S5r6oWi8gA\n4EMR+UJVHbfMUdWZwEyA3NxczcvLa1IMPp+Ppq4bSxZX43gmrtW7oE6NsazsYxod2+riMua8/5mj\nPT21DX+94XRO6tW8Ojae2V91WFyNE6u43EzdFAOhhTZ6B9uOICLnA/cC41T18BEsVS0O/rsZ8AEj\nmxGvMfEVhYJmZQeqmTInn6owxcoeGj+02UnemEjcJPqlwCAR6S8i6cAE4IizZ0RkJPAnAkm+JKS9\ni4i0DT7OAs4AQg/iGuNtzSxoVlur3PHyCrbtPujo+1Fub64+5djmRGeMKxGnblS1RkSmAu8CKcAs\nVV0jIg8Cy1R1PvA4kAm8HCy+9LWqjgNOBP4kIrUEPlQeqXO2jjHe1swR/bOLvuT9dSWO9hN7HsWD\n409qTmTGuOZqjl5VFwAL6rTdH/L4/HrW+wwcx7KMaTmaMaL/7Mud/C5csbKMVJ69JoeMNCtWZuLD\nLr8zpiE1YcoUuxjRf7e3glvnLidMrTJ+f9Vw+nazYmUmfizRG9OQJozoq/21TH2hgJ3lzg+JG88a\nwIVDj45WdMa4YonemIY0YY7+sXfWs3TrHkf7qf27ctdFx0crMmNcs0RvTEMaWQLhndXb+d9/bnG0\nd+/YlhkTR5JqxcpMAthvnTENaURRsy0793PXy6sc7SlthBkTR9LDipWZBLFEb0xDXI7oD1b5mfJ8\nfthiZXdfdDyjB1ixMpM4luiNaYiLg7Gqyq/eWM36b/c5Fr1wSDaTz7JiZSaxLNEb0xAXB2PnLd3G\nqwVFjsX6dmvP41cNJ3gRoTEJY4nemIZEGNGvLi7jgflrHIu0TW3DM5NG0aldWiyjM8YVS/TGNKSB\nEX3ZgWp++nw9xcq+fxJDjjkq1tEZ44olemMaUs+IvrZWuf2lFRTtcRYruzq3Dz/K7eNcz5gEsURv\nTEPqGdE/8/GXfLDeWaxsSM+j+PX4oXEIzBj3onrjEWOSTpgRff43B/j9e9862gPFykZZsTLjOTai\nN6YhYUb0v3pzU9hiZU/8aATHdmsfh6CMaRxL9MY0JMyIfvt+52I/Pfs4LhiSHYeAjGk8S/TGNCTM\niL6SI0+ZHDOgK3deODheERnTaK7m6EXkYuBJAneY+rOqPlKnvy3wN2AUsAu4WlW3Bvt+AVwP+IFb\nVfXdqEUftOTFR2HHegBq95ezZPVz0d5Es1lcjeOJuFQZXeM8q6YqJNH36NiWP1qxMuNxERO9iKQA\nTwEXAEXAUhGZX+eWgNcDe1R1oIhMAB4FrhaRIQTuMTsUOAZ4X0QGq6o/mm8iY+v7DD/4+f81OP82\nvcHiahwPxqUIfgIHW1PaCDN+nEOPjlaszHibmxH9qUChqm4GEJF5wHiOvMn3eGBa8PErwAwJXPc9\nHpinqpXAFhEpDL7evxra4IYNG8jLy3P9Jsq/XklmbZiJU2OiaMW3fhSh8oV7AOif1YG7P/NGki8t\nLaVz586JDsPB4mqcWMXlJtH3AraFPC8CRte3TPBm4mVAt2D74jrr9gq3ERGZDEwGSEtLo7S01E38\nAKRomFMgjImBWoS0NkLPDkLb2gpKS8NcUJUAfr+/UX8z8WJxNU6s4vLMefSqOhOYCZCbm6vLli1z\nve7KRy84curGmBg4a/YBtqf2YeXaAtqne+ZPBwCfz9eob8HxYnE1TnPiaqh4npvf1mIg9Hru3sG2\ncMsUiUgq0InAQVk36zab5l7Pkp3nAVBSUkKPHj2ivYlms7gax2txtUnvgL/n83Q4WOm5JG9MJG5+\nY5cCg0SkP4EkPQH4cZ1l5gPXEph7vxL4UFVVROYDL4jIEwQOxg4Coj70HnHehMOPfT4foz36SW1x\nuefFuNKefBUOhimJYIzHRUz0wTn3qcC7BE6vnKWqa0TkQWCZqs4H/gL8v+DB1t0EPgwILvcSgQO3\nNcDN0T7jxhhjTMNcfQdV1QXAgjpt94c8rgCuqmfd3wC/aUaMxhhjmsGu8jDGmCRnid4YY5KcJXpj\njElyluiNMSbJiXrwqlIR2QF81cTVs4CdUQwnWiyuxrG4GsfiapxkjKuvqnYP1+HJRN8cIrJMVXMT\nHUddFlfjWFyNY3E1TmuLy6ZujDEmyVmiN8aYJJeMiX5mogOoh8XVOBZX41hcjdOq4kq6OXpjjDFH\nSsYRvTHGmBCW6I0xJsm1+EQvIo+LyHoRWSUir4tI2PtwicjFIrJBRApF5J44xHWViKwRkVoRqfd0\nKRHZKiJfiMgKEXF/t5XYxxXv/dVVRBaKyKbgv13qWc4f3FcrgmWwYxVPg+9fRNqKyIvB/iUi0i9W\nsTQyrutEZEfIProhDjHNEpESEVldT7+IyB+DMa8SkZxYx+QyrjwRKQvZV/eHWy4GcfURkY9EZG3w\nb/FnYZaJ7j5T1Rb9A1wIpAYfPwo8GmaZFOBLYACQDqwEhsQ4rhOB4wEfkNvAcluBrDjur4hxJWh/\nPQbcE3x8T7j/x2BfeRz2UcT3D9wEPBt8PAF40SNxXQfMiNfvU3CbZwE5wOp6+i8B3gYEGAMs8Uhc\necBb8dxXwe32BHKCjzsCG8P8P0Z1n7X4Eb2qvqeqNcGniwncxaquwzc4V9Uq4NANzmMZ1zpV3RDL\nbTSFy7jivr+Cr/9c8PFzwPdjvL2GuHn/ofG+ApwnDd3LLX5xxZ2qLiJwH4r6jAf+pgGLgc4i0tMD\ncSWEqm5X1YLg433AOpz30o7qPmvxib6O/yDwKVhXuBuch71JeQIo8J6I5AdvkO4Fidhf2aq6Pfj4\nWyC7nuUyRGSZiCwWkVh9GLh5/4eXCQ40yoBuMYqnMXEBXBH8uv+KiPQJ0x9vXv77O01EVorI2yIy\nNN4bD075jQSW1OmK6j5rETe/FJH3gaPDdN2rqn8PLnMvgbtYzfFSXC6MVdViEekBLBSR9cGRSKLj\nirqG4gp9oqoqIvWd99s3uL8GAB+KyBeq+mW0Y23B3gTmqmqliNxI4FvHuQmOyasKCPw+lYvIJcAb\nBG53Ghcikgm8Ctymqntjua0WkehV9fyG+kXkOuAy4DwNTnDVEZOblEeKy+VrFAf/LRGR1wl8PW9W\noo9CXHHfXyLynYj0VNXtwa+oJfW8xqH9tVlEfARGQ9FO9G7e/6FlikQkFegE7IpyHI2OS1VDY/gz\ngWMfiRaT36fmCk2uqrpARJ4WkSxVjXmxMxFJI5Dk56jqa2EWieo+a/FTNyJyMXA3ME5VD9Sz2OEb\nnItIOoGDZzE7Y8MtEekgIh0PPSZwYDnsGQJxloj9degG8wT/dXzzEJEuItI2+DgLOIPA/Yijzc37\nD433SuDDegYZcY2rzjzuOALzv4k2H/hJ8EySMUBZyDRdwojI0YeOq4jIqQTyYaw/rAlu8y/AOlV9\nop7ForvP4n3EOdo/QCGBuawVwZ9DZ0IcAywIWe4SAke3vyQwhRHruH5AYF6tEvgOeLduXATOnlgZ\n/FnjlbgStL+6AR8Am4D3ga7B9lzgz8HHpwNfBPfXF8D1MYzH8f6BBwkMKAAygJeDv3+fAwNivY9c\nxvXb4O/SSuAj4IQ4xDQX2A5UB3+3rgd+Cvw02C/AU8GYv6CBs9DiHNfUkH21GDg9TnGNJXBsblVI\n3roklvvMSiAYY0ySa/FTN8YYYxpmid4YY5KcJXpjjElyluiNMSbJWaI3xpgkZ4neGGOSnCV6Y4xJ\ncv8f8sgbZnfFgmIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJ7TZCzyUH97",
        "colab_type": "text"
      },
      "source": [
        "### Leaky ReLU (Rectified Linear Unit)\n",
        "\n",
        "$$\\text{relu}(z) = \\text{z if }z<0\\;;\\;kz\\text{ otherwise with }k<<1$$\n",
        "\n",
        "$$\\frac{\\partial \\;\\text{relu}}{\\partial \\; z} = \\text{1 if }z<0\\;;\\;k\\text{ otherwise}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoJSTwSuUH97",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "a486f342-a8cc-46e0-daeb-991d02516e90"
      },
      "source": [
        "z = np.linspace(-2,2,100)\n",
        "\n",
        "relu = np.vectorize(lambda z: z if z>0 else .1*z)\n",
        "\n",
        "drelu = np.vectorize(lambda z: 1 if z>0 else .1)\n",
        "\n",
        "plt.plot(z, relu(z), lw=5, label=\"relu\")\n",
        "plt.plot(z, drelu(z), lw=5, label=\"grad relu\")\n",
        "plt.grid(); \n",
        "plt.axvline(0, color=\"black\");\n",
        "plt.axhline(0, color=\"black\");\n",
        "plt.legend()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7effd48e41d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJqSgCyFEmPg/Z6MolbrIMLcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBeaup9oUH9-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cO5EcNXSUH-B",
        "colab_type": "text"
      },
      "source": [
        "### load sample MNIST data as customary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW5RDD8qUH-C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eaa3d9ec-5f41-495b-88a7-a9eb8caeba41"
      },
      "source": [
        "mnist = pd.read_csv(\"local/data/mnist1.5k.csv.gz\", compression=\"gzip\", header=None).values\n",
        "X=mnist[:,1:785]/255.\n",
        "y=mnist[:,0]\n",
        "print(\"dimension de las imagenes y las clases\", X.shape, y.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dimension de las imagenes y las clases (1500, 784) (1500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iXzcb0jUH-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a16a944-05df-4549-82b2-95d0de7805d9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
        "X_train = X_train\n",
        "X_test  = X_test\n",
        "y_train_oh = np.eye(10)[y_train]\n",
        "y_test_oh  = np.eye(10)[y_test]\n",
        "print(X_train.shape, y_train_oh.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1200, 784) (1200, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmoxgIGkUH-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, concatenate, Input\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTl-dXJ9UH-J",
        "colab_type": "text"
      },
      "source": [
        "### A basic multi layered dense model\n",
        "\n",
        "observe that the function allows us to parametrize the number of hidden layers and their activation function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5wi-OteUH-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(input_dim=784, output_dim=10, num_hidden_layers=6, hidden_size=10, activation=\"relu\"):\n",
        "\n",
        "    clear_session()\n",
        "    model = Sequential()\n",
        "    model.add(Dense(hidden_size, activation=activation, input_dim=input_dim, name=\"Layer_%02d_Input\"%(0)))\n",
        "    \n",
        "    for i in range(num_hidden_layers):\n",
        "        model.add(Dense(hidden_size, activation=activation, name=\"Layer_%02d_Hidden\"%(i+1)))\n",
        "   \n",
        "    model.add(Dense(output_dim, activation=\"softmax\", name=\"Layer_%02d_Output\"%(num_hidden_layers+1)))\n",
        "        \n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.reset_states()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdjyzRhkUH-N",
        "colab_type": "text"
      },
      "source": [
        "### SIGMOID activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "IRua6cxAUH-N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6af87062-3947-46a5-c78f-c50627fb7c1e"
      },
      "source": [
        "model = get_model(num_hidden_layers=10, activation=\"sigmoid\")\n",
        "!rm -rf log/sigmoid\n",
        "tb_callback = keras.callbacks.TensorBoard(log_dir='./log/sigmoid', histogram_freq=1,  write_grads=True, write_graph=True, write_images=True)\n",
        "model.fit(X_train, y_train_oh, epochs=30, batch_size=32, validation_data=(X_test, y_test_oh), callbacks=[tb_callback])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
            "Train on 1200 samples, validate on 300 samples\n",
            "Epoch 1/30\n",
            "1200/1200 [==============================] - 1s 1ms/sample - loss: 2.3318 - accuracy: 0.1000 - val_loss: 2.3345 - val_accuracy: 0.0867\n",
            "Epoch 2/30\n",
            "1200/1200 [==============================] - 0s 150us/sample - loss: 2.3110 - accuracy: 0.0933 - val_loss: 2.3159 - val_accuracy: 0.0933\n",
            "Epoch 3/30\n",
            "1200/1200 [==============================] - 0s 137us/sample - loss: 2.3043 - accuracy: 0.1025 - val_loss: 2.3094 - val_accuracy: 0.1433\n",
            "Epoch 4/30\n",
            "1200/1200 [==============================] - 0s 155us/sample - loss: 2.3007 - accuracy: 0.1192 - val_loss: 2.3049 - val_accuracy: 0.1433\n",
            "Epoch 5/30\n",
            "1200/1200 [==============================] - 0s 138us/sample - loss: 2.3000 - accuracy: 0.1192 - val_loss: 2.3023 - val_accuracy: 0.1433\n",
            "Epoch 6/30\n",
            "1200/1200 [==============================] - 0s 140us/sample - loss: 2.3000 - accuracy: 0.1192 - val_loss: 2.3001 - val_accuracy: 0.1433\n",
            "Epoch 7/30\n",
            "1200/1200 [==============================] - 0s 144us/sample - loss: 2.2997 - accuracy: 0.1192 - val_loss: 2.2999 - val_accuracy: 0.1433\n",
            "Epoch 8/30\n",
            "1200/1200 [==============================] - 0s 148us/sample - loss: 2.2992 - accuracy: 0.1192 - val_loss: 2.2988 - val_accuracy: 0.1433\n",
            "Epoch 9/30\n",
            "1200/1200 [==============================] - 0s 151us/sample - loss: 2.2997 - accuracy: 0.1192 - val_loss: 2.2985 - val_accuracy: 0.1433\n",
            "Epoch 10/30\n",
            "1200/1200 [==============================] - 0s 152us/sample - loss: 2.2998 - accuracy: 0.1192 - val_loss: 2.2985 - val_accuracy: 0.1433\n",
            "Epoch 11/30\n",
            "1200/1200 [==============================] - 0s 145us/sample - loss: 2.2995 - accuracy: 0.1192 - val_loss: 2.2988 - val_accuracy: 0.1433\n",
            "Epoch 12/30\n",
            "1200/1200 [==============================] - 0s 157us/sample - loss: 2.2996 - accuracy: 0.1192 - val_loss: 2.2985 - val_accuracy: 0.1433\n",
            "Epoch 13/30\n",
            "1200/1200 [==============================] - 0s 139us/sample - loss: 2.2998 - accuracy: 0.1192 - val_loss: 2.2999 - val_accuracy: 0.1433\n",
            "Epoch 14/30\n",
            "1200/1200 [==============================] - 0s 161us/sample - loss: 2.2997 - accuracy: 0.1192 - val_loss: 2.2993 - val_accuracy: 0.1433\n",
            "Epoch 15/30\n",
            "1200/1200 [==============================] - 0s 160us/sample - loss: 2.2994 - accuracy: 0.1192 - val_loss: 2.2998 - val_accuracy: 0.1433\n",
            "Epoch 16/30\n",
            "1200/1200 [==============================] - 0s 145us/sample - loss: 2.3000 - accuracy: 0.1192 - val_loss: 2.2985 - val_accuracy: 0.1433\n",
            "Epoch 17/30\n",
            "1200/1200 [==============================] - 0s 148us/sample - loss: 2.2994 - accuracy: 0.1192 - val_loss: 2.2984 - val_accuracy: 0.1433\n",
            "Epoch 18/30\n",
            "1200/1200 [==============================] - 0s 150us/sample - loss: 2.2999 - accuracy: 0.1192 - val_loss: 2.2991 - val_accuracy: 0.1433\n",
            "Epoch 19/30\n",
            "1200/1200 [==============================] - 0s 157us/sample - loss: 2.3000 - accuracy: 0.1192 - val_loss: 2.2987 - val_accuracy: 0.1433\n",
            "Epoch 20/30\n",
            "1200/1200 [==============================] - 0s 151us/sample - loss: 2.2997 - accuracy: 0.1192 - val_loss: 2.2993 - val_accuracy: 0.1433\n",
            "Epoch 21/30\n",
            "1200/1200 [==============================] - 0s 160us/sample - loss: 2.3000 - accuracy: 0.1192 - val_loss: 2.2986 - val_accuracy: 0.1433\n",
            "Epoch 22/30\n",
            "1200/1200 [==============================] - 0s 149us/sample - loss: 2.2996 - accuracy: 0.1192 - val_loss: 2.2978 - val_accuracy: 0.1433\n",
            "Epoch 23/30\n",
            "1200/1200 [==============================] - 0s 145us/sample - loss: 2.2991 - accuracy: 0.1192 - val_loss: 2.2981 - val_accuracy: 0.1433\n",
            "Epoch 24/30\n",
            "1200/1200 [==============================] - 0s 159us/sample - loss: 2.2998 - accuracy: 0.1192 - val_loss: 2.2989 - val_accuracy: 0.1433\n",
            "Epoch 25/30\n",
            "1200/1200 [==============================] - 0s 154us/sample - loss: 2.2995 - accuracy: 0.1192 - val_loss: 2.2991 - val_accuracy: 0.1433\n",
            "Epoch 26/30\n",
            "1200/1200 [==============================] - 0s 146us/sample - loss: 2.3001 - accuracy: 0.1192 - val_loss: 2.2987 - val_accuracy: 0.1433\n",
            "Epoch 27/30\n",
            "1200/1200 [==============================] - 0s 147us/sample - loss: 2.2995 - accuracy: 0.1192 - val_loss: 2.3000 - val_accuracy: 0.1433\n",
            "Epoch 28/30\n",
            "1200/1200 [==============================] - 0s 152us/sample - loss: 2.3001 - accuracy: 0.1192 - val_loss: 2.2997 - val_accuracy: 0.1433\n",
            "Epoch 29/30\n",
            "1200/1200 [==============================] - 0s 148us/sample - loss: 2.3003 - accuracy: 0.1192 - val_loss: 2.2972 - val_accuracy: 0.1433\n",
            "Epoch 30/30\n",
            "1200/1200 [==============================] - 0s 155us/sample - loss: 2.2998 - accuracy: 0.1192 - val_loss: 2.2980 - val_accuracy: 0.1433\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7effccd01668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbfRphpAUH-Q",
        "colab_type": "text"
      },
      "source": [
        "### RELU activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "yHNZjjBSUH-R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a569f002-af25-460f-d0de-3897e8b83c8d"
      },
      "source": [
        "model = get_model(num_hidden_layers=10, activation=\"relu\")\n",
        "!rm -rf log/relu\n",
        "tb_callback = keras.callbacks.TensorBoard(log_dir='./log/relu', histogram_freq=1,  write_grads=True, write_graph=True, write_images=True)\n",
        "model.fit(X_train, y_train_oh, epochs=30, batch_size=32, validation_data=(X_test, y_test_oh), callbacks=[tb_callback])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
            "Train on 1200 samples, validate on 300 samples\n",
            "Epoch 1/30\n",
            "1200/1200 [==============================] - 1s 791us/sample - loss: 2.2966 - accuracy: 0.1500 - val_loss: 2.2831 - val_accuracy: 0.1467\n",
            "Epoch 2/30\n",
            "1200/1200 [==============================] - 0s 157us/sample - loss: 2.1956 - accuracy: 0.1842 - val_loss: 2.1519 - val_accuracy: 0.1767\n",
            "Epoch 3/30\n",
            "1200/1200 [==============================] - 0s 150us/sample - loss: 2.0006 - accuracy: 0.2225 - val_loss: 1.9934 - val_accuracy: 0.2433\n",
            "Epoch 4/30\n",
            "1200/1200 [==============================] - 0s 156us/sample - loss: 1.8247 - accuracy: 0.2117 - val_loss: 1.8681 - val_accuracy: 0.2400\n",
            "Epoch 5/30\n",
            "1200/1200 [==============================] - 0s 241us/sample - loss: 1.6695 - accuracy: 0.2733 - val_loss: 1.7260 - val_accuracy: 0.3133\n",
            "Epoch 6/30\n",
            "1200/1200 [==============================] - 0s 154us/sample - loss: 1.5062 - accuracy: 0.3950 - val_loss: 1.6061 - val_accuracy: 0.4133\n",
            "Epoch 7/30\n",
            "1200/1200 [==============================] - 0s 144us/sample - loss: 1.3165 - accuracy: 0.4342 - val_loss: 1.6024 - val_accuracy: 0.4233\n",
            "Epoch 8/30\n",
            "1200/1200 [==============================] - 0s 139us/sample - loss: 1.1972 - accuracy: 0.4883 - val_loss: 1.5921 - val_accuracy: 0.4933\n",
            "Epoch 9/30\n",
            "1200/1200 [==============================] - 0s 141us/sample - loss: 1.1051 - accuracy: 0.5367 - val_loss: 1.7167 - val_accuracy: 0.5133\n",
            "Epoch 10/30\n",
            "1200/1200 [==============================] - 0s 141us/sample - loss: 1.0284 - accuracy: 0.5600 - val_loss: 1.6552 - val_accuracy: 0.4633\n",
            "Epoch 11/30\n",
            "1200/1200 [==============================] - 0s 145us/sample - loss: 0.9890 - accuracy: 0.5758 - val_loss: 1.7537 - val_accuracy: 0.5233\n",
            "Epoch 12/30\n",
            "1200/1200 [==============================] - 0s 139us/sample - loss: 0.9423 - accuracy: 0.5942 - val_loss: 1.7436 - val_accuracy: 0.5033\n",
            "Epoch 13/30\n",
            "1200/1200 [==============================] - 0s 137us/sample - loss: 0.8690 - accuracy: 0.6492 - val_loss: 1.7665 - val_accuracy: 0.5633\n",
            "Epoch 14/30\n",
            "1200/1200 [==============================] - 0s 150us/sample - loss: 0.8438 - accuracy: 0.6392 - val_loss: 1.7454 - val_accuracy: 0.5567\n",
            "Epoch 15/30\n",
            "1200/1200 [==============================] - 0s 159us/sample - loss: 0.7849 - accuracy: 0.6792 - val_loss: 1.9313 - val_accuracy: 0.5800\n",
            "Epoch 16/30\n",
            "1200/1200 [==============================] - 0s 154us/sample - loss: 0.7558 - accuracy: 0.7008 - val_loss: 1.8554 - val_accuracy: 0.5867\n",
            "Epoch 17/30\n",
            "1200/1200 [==============================] - 0s 148us/sample - loss: 0.7106 - accuracy: 0.7217 - val_loss: 1.9866 - val_accuracy: 0.5900\n",
            "Epoch 18/30\n",
            "1200/1200 [==============================] - 0s 151us/sample - loss: 0.6789 - accuracy: 0.7550 - val_loss: 2.0375 - val_accuracy: 0.6100\n",
            "Epoch 19/30\n",
            "1200/1200 [==============================] - 0s 152us/sample - loss: 0.6371 - accuracy: 0.7775 - val_loss: 1.9287 - val_accuracy: 0.6133\n",
            "Epoch 20/30\n",
            "1200/1200 [==============================] - 0s 147us/sample - loss: 0.6300 - accuracy: 0.7733 - val_loss: 2.0904 - val_accuracy: 0.5800\n",
            "Epoch 21/30\n",
            "1200/1200 [==============================] - 0s 150us/sample - loss: 0.5994 - accuracy: 0.7858 - val_loss: 2.0640 - val_accuracy: 0.5833\n",
            "Epoch 22/30\n",
            "1200/1200 [==============================] - 0s 140us/sample - loss: 0.5558 - accuracy: 0.8183 - val_loss: 2.1383 - val_accuracy: 0.5833\n",
            "Epoch 23/30\n",
            "1200/1200 [==============================] - 0s 159us/sample - loss: 0.5219 - accuracy: 0.8283 - val_loss: 2.2409 - val_accuracy: 0.6300\n",
            "Epoch 24/30\n",
            "1200/1200 [==============================] - 0s 156us/sample - loss: 0.5152 - accuracy: 0.8242 - val_loss: 2.2107 - val_accuracy: 0.6067\n",
            "Epoch 25/30\n",
            "1200/1200 [==============================] - 0s 139us/sample - loss: 0.4769 - accuracy: 0.8492 - val_loss: 2.2650 - val_accuracy: 0.6067\n",
            "Epoch 26/30\n",
            "1200/1200 [==============================] - 0s 169us/sample - loss: 0.4303 - accuracy: 0.8675 - val_loss: 2.3513 - val_accuracy: 0.6600\n",
            "Epoch 27/30\n",
            "1200/1200 [==============================] - 0s 139us/sample - loss: 0.4653 - accuracy: 0.8408 - val_loss: 2.5494 - val_accuracy: 0.6300\n",
            "Epoch 28/30\n",
            "1200/1200 [==============================] - 0s 143us/sample - loss: 0.4194 - accuracy: 0.8667 - val_loss: 2.5070 - val_accuracy: 0.6667\n",
            "Epoch 29/30\n",
            "1200/1200 [==============================] - 0s 157us/sample - loss: 0.3761 - accuracy: 0.8867 - val_loss: 2.5212 - val_accuracy: 0.6900\n",
            "Epoch 30/30\n",
            "1200/1200 [==============================] - 0s 140us/sample - loss: 0.3688 - accuracy: 0.8858 - val_loss: 2.7497 - val_accuracy: 0.6467\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7effcba75550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TYgHSlJUH-T",
        "colab_type": "text"
      },
      "source": [
        "### Leaky RELU activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "xKV9L6RBUH-U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a2ecec17-905c-4800-a468-89f45973d7dc"
      },
      "source": [
        "import tensorflow as tf\n",
        "model = get_model(num_hidden_layers=10, activation=tf.nn.leaky_relu)\n",
        "!rm -rf log/leaky_relu\n",
        "tb_callback = keras.callbacks.TensorBoard(log_dir='./log/leaky_relu', histogram_freq=1,  write_grads=True, write_graph=True, write_images=True)\n",
        "model.fit(X_train, y_train_oh, epochs=30, batch_size=32, validation_data=(X_test, y_test_oh), callbacks=[tb_callback])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
            "Train on 1200 samples, validate on 300 samples\n",
            "Epoch 1/30\n",
            "1200/1200 [==============================] - 1s 763us/sample - loss: 2.2942 - accuracy: 0.1192 - val_loss: 2.2463 - val_accuracy: 0.1433\n",
            "Epoch 2/30\n",
            "1200/1200 [==============================] - 0s 148us/sample - loss: 2.1663 - accuracy: 0.1575 - val_loss: 2.0257 - val_accuracy: 0.2300\n",
            "Epoch 3/30\n",
            "1200/1200 [==============================] - 0s 156us/sample - loss: 2.0329 - accuracy: 0.2158 - val_loss: 1.9318 - val_accuracy: 0.2300\n",
            "Epoch 4/30\n",
            "1200/1200 [==============================] - 0s 144us/sample - loss: 1.9276 - accuracy: 0.2150 - val_loss: 1.8053 - val_accuracy: 0.2300\n",
            "Epoch 5/30\n",
            "1200/1200 [==============================] - 0s 148us/sample - loss: 1.7634 - accuracy: 0.2292 - val_loss: 1.6782 - val_accuracy: 0.2533\n",
            "Epoch 6/30\n",
            "1200/1200 [==============================] - 0s 141us/sample - loss: 1.6394 - accuracy: 0.2633 - val_loss: 1.6287 - val_accuracy: 0.2900\n",
            "Epoch 7/30\n",
            "1200/1200 [==============================] - 0s 137us/sample - loss: 1.5534 - accuracy: 0.3500 - val_loss: 1.5477 - val_accuracy: 0.4100\n",
            "Epoch 8/30\n",
            "1200/1200 [==============================] - 0s 145us/sample - loss: 1.4491 - accuracy: 0.3767 - val_loss: 1.4647 - val_accuracy: 0.4200\n",
            "Epoch 9/30\n",
            "1200/1200 [==============================] - 0s 145us/sample - loss: 1.3259 - accuracy: 0.4100 - val_loss: 1.4384 - val_accuracy: 0.4367\n",
            "Epoch 10/30\n",
            "1200/1200 [==============================] - 0s 145us/sample - loss: 1.2360 - accuracy: 0.4758 - val_loss: 1.3836 - val_accuracy: 0.5000\n",
            "Epoch 11/30\n",
            "1200/1200 [==============================] - 0s 143us/sample - loss: 1.1378 - accuracy: 0.5583 - val_loss: 1.3734 - val_accuracy: 0.5033\n",
            "Epoch 12/30\n",
            "1200/1200 [==============================] - 0s 155us/sample - loss: 1.0736 - accuracy: 0.5942 - val_loss: 1.3026 - val_accuracy: 0.6067\n",
            "Epoch 13/30\n",
            "1200/1200 [==============================] - 0s 144us/sample - loss: 0.9666 - accuracy: 0.6642 - val_loss: 1.2702 - val_accuracy: 0.5567\n",
            "Epoch 14/30\n",
            "1200/1200 [==============================] - 0s 145us/sample - loss: 0.9262 - accuracy: 0.6617 - val_loss: 1.2845 - val_accuracy: 0.5667\n",
            "Epoch 15/30\n",
            "1200/1200 [==============================] - 0s 146us/sample - loss: 0.8857 - accuracy: 0.6883 - val_loss: 1.2954 - val_accuracy: 0.5833\n",
            "Epoch 16/30\n",
            "1200/1200 [==============================] - 0s 141us/sample - loss: 0.8037 - accuracy: 0.7125 - val_loss: 1.3578 - val_accuracy: 0.5900\n",
            "Epoch 17/30\n",
            "1200/1200 [==============================] - 0s 152us/sample - loss: 0.7537 - accuracy: 0.7392 - val_loss: 1.3278 - val_accuracy: 0.6600\n",
            "Epoch 18/30\n",
            "1200/1200 [==============================] - 0s 147us/sample - loss: 0.6916 - accuracy: 0.7758 - val_loss: 1.4566 - val_accuracy: 0.6033\n",
            "Epoch 19/30\n",
            "1200/1200 [==============================] - 0s 148us/sample - loss: 0.6612 - accuracy: 0.7708 - val_loss: 1.3057 - val_accuracy: 0.6267\n",
            "Epoch 20/30\n",
            "1200/1200 [==============================] - 0s 150us/sample - loss: 0.6395 - accuracy: 0.7750 - val_loss: 1.3881 - val_accuracy: 0.6467\n",
            "Epoch 21/30\n",
            "1200/1200 [==============================] - 0s 157us/sample - loss: 0.5702 - accuracy: 0.8017 - val_loss: 1.3874 - val_accuracy: 0.6733\n",
            "Epoch 22/30\n",
            "1200/1200 [==============================] - 0s 143us/sample - loss: 0.5066 - accuracy: 0.8225 - val_loss: 1.3868 - val_accuracy: 0.6700\n",
            "Epoch 23/30\n",
            "1200/1200 [==============================] - 0s 152us/sample - loss: 0.4793 - accuracy: 0.8283 - val_loss: 1.6420 - val_accuracy: 0.6567\n",
            "Epoch 24/30\n",
            "1200/1200 [==============================] - 0s 146us/sample - loss: 0.4697 - accuracy: 0.8300 - val_loss: 1.5471 - val_accuracy: 0.7100\n",
            "Epoch 25/30\n",
            "1200/1200 [==============================] - 0s 140us/sample - loss: 0.4399 - accuracy: 0.8450 - val_loss: 1.6849 - val_accuracy: 0.6600\n",
            "Epoch 26/30\n",
            "1200/1200 [==============================] - 0s 145us/sample - loss: 0.4191 - accuracy: 0.8483 - val_loss: 1.6577 - val_accuracy: 0.6633\n",
            "Epoch 27/30\n",
            "1200/1200 [==============================] - 0s 144us/sample - loss: 0.3936 - accuracy: 0.8658 - val_loss: 1.7763 - val_accuracy: 0.6833\n",
            "Epoch 28/30\n",
            "1200/1200 [==============================] - 0s 153us/sample - loss: 0.3695 - accuracy: 0.8733 - val_loss: 1.9116 - val_accuracy: 0.6933\n",
            "Epoch 29/30\n",
            "1200/1200 [==============================] - 0s 150us/sample - loss: 0.3508 - accuracy: 0.8833 - val_loss: 1.9878 - val_accuracy: 0.6633\n",
            "Epoch 30/30\n",
            "1200/1200 [==============================] - 0s 142us/sample - loss: 0.3413 - accuracy: 0.8875 - val_loss: 1.9426 - val_accuracy: 0.7033\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7effcb03c588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exW0_JcbUH-W",
        "colab_type": "text"
      },
      "source": [
        "### SIGMOID activation but longer run (epochs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "iPJDDeKJUH-X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b39dec94-c552-423a-fd24-565beeaec453"
      },
      "source": [
        "model = get_model(num_hidden_layers=10, activation=\"sigmoid\")\n",
        "!rm -rf log/sigmoid_longrun\n",
        "tb_callback = keras.callbacks.TensorBoard(log_dir='./log/sigmoid_longrun', histogram_freq=1,  write_grads=True, write_graph=True, write_images=True)\n",
        "model.fit(X_train, y_train_oh, epochs=300, batch_size=32, validation_data=(X_test, y_test_oh), callbacks=[tb_callback])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
            "Train on 1200 samples, validate on 300 samples\n",
            "Epoch 1/300\n",
            "1200/1200 [==============================] - 1s 765us/sample - loss: 2.3321 - accuracy: 0.1000 - val_loss: 2.3207 - val_accuracy: 0.1133\n",
            "Epoch 2/300\n",
            "1200/1200 [==============================] - 0s 144us/sample - loss: 2.3131 - accuracy: 0.1000 - val_loss: 2.3067 - val_accuracy: 0.1133\n",
            "Epoch 3/300\n",
            "1200/1200 [==============================] - 0s 152us/sample - loss: 2.3051 - accuracy: 0.1000 - val_loss: 2.3010 - val_accuracy: 0.1133\n",
            "Epoch 4/300\n",
            "1200/1200 [==============================] - 0s 139us/sample - loss: 2.3023 - accuracy: 0.1175 - val_loss: 2.3009 - val_accuracy: 0.1433\n",
            "Epoch 5/300\n",
            "1200/1200 [==============================] - 0s 141us/sample - loss: 2.3005 - accuracy: 0.1192 - val_loss: 2.2974 - val_accuracy: 0.1433\n",
            "Epoch 6/300\n",
            "1200/1200 [==============================] - 0s 154us/sample - loss: 2.2997 - accuracy: 0.1192 - val_loss: 2.2974 - val_accuracy: 0.1433\n",
            "Epoch 7/300\n",
            "1200/1200 [==============================] - 0s 152us/sample - loss: 2.2996 - accuracy: 0.1192 - val_loss: 2.2991 - val_accuracy: 0.1433\n",
            "Epoch 8/300\n",
            "1200/1200 [==============================] - 0s 157us/sample - loss: 2.2996 - accuracy: 0.1192 - val_loss: 2.2976 - val_accuracy: 0.1433\n",
            "Epoch 9/300\n",
            "1200/1200 [==============================] - 0s 142us/sample - loss: 2.2991 - accuracy: 0.1192 - val_loss: 2.2989 - val_accuracy: 0.1433\n",
            "Epoch 10/300\n",
            "1200/1200 [==============================] - 0s 144us/sample - loss: 2.3000 - accuracy: 0.1192 - val_loss: 2.2991 - val_accuracy: 0.1433\n",
            "Epoch 11/300\n",
            "1200/1200 [==============================] - 0s 142us/sample - loss: 2.2996 - accuracy: 0.1192 - val_loss: 2.2994 - val_accuracy: 0.1433\n",
            "Epoch 12/300\n",
            "1200/1200 [==============================] - 0s 142us/sample - loss: 2.2994 - accuracy: 0.1192 - val_loss: 2.2992 - val_accuracy: 0.1433\n",
            "Epoch 13/300\n",
            "1200/1200 [==============================] - 0s 143us/sample - loss: 2.2994 - accuracy: 0.1192 - val_loss: 2.2992 - val_accuracy: 0.1433\n",
            "Epoch 14/300\n",
            "1200/1200 [==============================] - 0s 153us/sample - loss: 2.2997 - accuracy: 0.1192 - val_loss: 2.2992 - val_accuracy: 0.1433\n",
            "Epoch 15/300\n",
            "1200/1200 [==============================] - 0s 153us/sample - loss: 2.2993 - accuracy: 0.1192 - val_loss: 2.2995 - val_accuracy: 0.1433\n",
            "Epoch 16/300\n",
            "1200/1200 [==============================] - 0s 152us/sample - loss: 2.2998 - accuracy: 0.1192 - val_loss: 2.2985 - val_accuracy: 0.1433\n",
            "Epoch 17/300\n",
            "1200/1200 [==============================] - 0s 163us/sample - loss: 2.2993 - accuracy: 0.1192 - val_loss: 2.2993 - val_accuracy: 0.1433\n",
            "Epoch 18/300\n",
            "1200/1200 [==============================] - 0s 141us/sample - loss: 2.2997 - accuracy: 0.1192 - val_loss: 2.2986 - val_accuracy: 0.1433\n",
            "Epoch 19/300\n",
            "1200/1200 [==============================] - 0s 155us/sample - loss: 2.2994 - accuracy: 0.1192 - val_loss: 2.2998 - val_accuracy: 0.1433\n",
            "Epoch 20/300\n",
            "1200/1200 [==============================] - 0s 146us/sample - loss: 2.2998 - accuracy: 0.1192 - val_loss: 2.2978 - val_accuracy: 0.1433\n",
            "Epoch 21/300\n",
            "1200/1200 [==============================] - 0s 141us/sample - loss: 2.2999 - accuracy: 0.1192 - val_loss: 2.2975 - val_accuracy: 0.1433\n",
            "Epoch 22/300\n",
            "1200/1200 [==============================] - 0s 145us/sample - loss: 2.2993 - accuracy: 0.1192 - val_loss: 2.2999 - val_accuracy: 0.1433\n",
            "Epoch 23/300\n",
            "1200/1200 [==============================] - 0s 134us/sample - loss: 2.2997 - accuracy: 0.1192 - val_loss: 2.3008 - val_accuracy: 0.1433\n",
            "Epoch 24/300\n",
            "1200/1200 [==============================] - 0s 139us/sample - loss: 2.2992 - accuracy: 0.1192 - val_loss: 2.2988 - val_accuracy: 0.1433\n",
            "Epoch 25/300\n",
            "1200/1200 [==============================] - 0s 144us/sample - loss: 2.2995 - accuracy: 0.1192 - val_loss: 2.2983 - val_accuracy: 0.1433\n",
            "Epoch 26/300\n",
            "1200/1200 [==============================] - 0s 151us/sample - loss: 2.3002 - accuracy: 0.1192 - val_loss: 2.2987 - val_accuracy: 0.1433\n",
            "Epoch 27/300\n",
            "1200/1200 [==============================] - 0s 143us/sample - loss: 2.2997 - accuracy: 0.1192 - val_loss: 2.2985 - val_accuracy: 0.1433\n",
            "Epoch 28/300\n",
            "1200/1200 [==============================] - 0s 156us/sample - loss: 2.2994 - accuracy: 0.1192 - val_loss: 2.3003 - val_accuracy: 0.1433\n",
            "Epoch 29/300\n",
            "1200/1200 [==============================] - 0s 145us/sample - loss: 2.2995 - accuracy: 0.1192 - val_loss: 2.2994 - val_accuracy: 0.1433\n",
            "Epoch 30/300\n",
            "1200/1200 [==============================] - 0s 141us/sample - loss: 2.2994 - accuracy: 0.1192 - val_loss: 2.2986 - val_accuracy: 0.1433\n",
            "Epoch 31/300\n",
            "1200/1200 [==============================] - 0s 146us/sample - loss: 2.2993 - accuracy: 0.1192 - val_loss: 2.2988 - val_accuracy: 0.1433\n",
            "Epoch 32/300\n",
            "1200/1200 [==============================] - 0s 149us/sample - loss: 2.2997 - accuracy: 0.1192 - val_loss: 2.2981 - val_accuracy: 0.1433\n",
            "Epoch 33/300\n",
            "1200/1200 [==============================] - 0s 148us/sample - loss: 2.2995 - accuracy: 0.1192 - val_loss: 2.2993 - val_accuracy: 0.1433\n",
            "Epoch 34/300\n",
            "1200/1200 [==============================] - 0s 159us/sample - loss: 2.2997 - accuracy: 0.1192 - val_loss: 2.2993 - val_accuracy: 0.1433\n",
            "Epoch 35/300\n",
            "1200/1200 [==============================] - 0s 145us/sample - loss: 2.2995 - accuracy: 0.1192 - val_loss: 2.2990 - val_accuracy: 0.1433\n",
            "Epoch 36/300\n",
            "1200/1200 [==============================] - 0s 142us/sample - loss: 2.2999 - accuracy: 0.1192 - val_loss: 2.2996 - val_accuracy: 0.1433\n",
            "Epoch 37/300\n",
            "1200/1200 [==============================] - 0s 144us/sample - loss: 2.2996 - accuracy: 0.1192 - val_loss: 2.2995 - val_accuracy: 0.1433\n",
            "Epoch 38/300\n",
            "1200/1200 [==============================] - 0s 141us/sample - loss: 2.2995 - accuracy: 0.1192 - val_loss: 2.2988 - val_accuracy: 0.1433\n",
            "Epoch 39/300\n",
            "1200/1200 [==============================] - 0s 139us/sample - loss: 2.3000 - accuracy: 0.1192 - val_loss: 2.2986 - val_accuracy: 0.1433\n",
            "Epoch 40/300\n",
            "1200/1200 [==============================] - 0s 148us/sample - loss: 2.2996 - accuracy: 0.1192 - val_loss: 2.2995 - val_accuracy: 0.1433\n",
            "Epoch 41/300\n",
            "1200/1200 [==============================] - 0s 164us/sample - loss: 2.2999 - accuracy: 0.1192 - val_loss: 2.2988 - val_accuracy: 0.1433\n",
            "Epoch 42/300\n",
            "1200/1200 [==============================] - 0s 153us/sample - loss: 2.2996 - accuracy: 0.1192 - val_loss: 2.2992 - val_accuracy: 0.1433\n",
            "Epoch 43/300\n",
            "1200/1200 [==============================] - 0s 151us/sample - loss: 2.3002 - accuracy: 0.1192 - val_loss: 2.2986 - val_accuracy: 0.1433\n",
            "Epoch 44/300\n",
            "1200/1200 [==============================] - 0s 155us/sample - loss: 2.2995 - accuracy: 0.1192 - val_loss: 2.2982 - val_accuracy: 0.1433\n",
            "Epoch 45/300\n",
            "1200/1200 [==============================] - 0s 146us/sample - loss: 2.2993 - accuracy: 0.1192 - val_loss: 2.2993 - val_accuracy: 0.1433\n",
            "Epoch 46/300\n",
            "1200/1200 [==============================] - 0s 139us/sample - loss: 2.2996 - accuracy: 0.1192 - val_loss: 2.3004 - val_accuracy: 0.1433\n",
            "Epoch 47/300\n",
            "1200/1200 [==============================] - 0s 152us/sample - loss: 2.2999 - accuracy: 0.1192 - val_loss: 2.3000 - val_accuracy: 0.1433\n",
            "Epoch 48/300\n",
            "1200/1200 [==============================] - 0s 138us/sample - loss: 2.2991 - accuracy: 0.1192 - val_loss: 2.2990 - val_accuracy: 0.1433\n",
            "Epoch 49/300\n",
            "1200/1200 [==============================] - 0s 141us/sample - loss: 2.2993 - accuracy: 0.1192 - val_loss: 2.2981 - val_accuracy: 0.1433\n",
            "Epoch 50/300\n",
            "1200/1200 [==============================] - 0s 150us/sample - loss: 2.2997 - accuracy: 0.1192 - val_loss: 2.2994 - val_accuracy: 0.1433\n",
            "Epoch 51/300\n",
            "1200/1200 [==============================] - 0s 155us/sample - loss: 2.2994 - accuracy: 0.1192 - val_loss: 2.2995 - val_accuracy: 0.1433\n",
            "Epoch 52/300\n",
            "1200/1200 [==============================] - 0s 140us/sample - loss: 2.2999 - accuracy: 0.1192 - val_loss: 2.2997 - val_accuracy: 0.1433\n",
            "Epoch 53/300\n",
            "1200/1200 [==============================] - 0s 151us/sample - loss: 2.2996 - accuracy: 0.1192 - val_loss: 2.2996 - val_accuracy: 0.1433\n",
            "Epoch 54/300\n",
            "1200/1200 [==============================] - 0s 145us/sample - loss: 2.2993 - accuracy: 0.1192 - val_loss: 2.2994 - val_accuracy: 0.1433\n",
            "Epoch 55/300\n",
            "1200/1200 [==============================] - 0s 172us/sample - loss: 2.2997 - accuracy: 0.1192 - val_loss: 2.2990 - val_accuracy: 0.1433\n",
            "Epoch 56/300\n",
            "1200/1200 [==============================] - 0s 145us/sample - loss: 2.2994 - accuracy: 0.1192 - val_loss: 2.2990 - val_accuracy: 0.1433\n",
            "Epoch 57/300\n",
            "1200/1200 [==============================] - 0s 149us/sample - loss: 2.2994 - accuracy: 0.1192 - val_loss: 2.2989 - val_accuracy: 0.1433\n",
            "Epoch 58/300\n",
            "1200/1200 [==============================] - 0s 142us/sample - loss: 2.3001 - accuracy: 0.1192 - val_loss: 2.3001 - val_accuracy: 0.1433\n",
            "Epoch 59/300\n",
            "1200/1200 [==============================] - 0s 148us/sample - loss: 2.2992 - accuracy: 0.1192 - val_loss: 2.2998 - val_accuracy: 0.1433\n",
            "Epoch 60/300\n",
            "1200/1200 [==============================] - 0s 144us/sample - loss: 2.2994 - accuracy: 0.1192 - val_loss: 2.2989 - val_accuracy: 0.1433\n",
            "Epoch 61/300\n",
            "1200/1200 [==============================] - 0s 147us/sample - loss: 2.2992 - accuracy: 0.1192 - val_loss: 2.2992 - val_accuracy: 0.1433\n",
            "Epoch 62/300\n",
            "1200/1200 [==============================] - 0s 146us/sample - loss: 2.2992 - accuracy: 0.1192 - val_loss: 2.2988 - val_accuracy: 0.1433\n",
            "Epoch 63/300\n",
            "1200/1200 [==============================] - 0s 148us/sample - loss: 2.2999 - accuracy: 0.1192 - val_loss: 2.2982 - val_accuracy: 0.1433\n",
            "Epoch 64/300\n",
            "1200/1200 [==============================] - 0s 138us/sample - loss: 2.2993 - accuracy: 0.1192 - val_loss: 2.2996 - val_accuracy: 0.1433\n",
            "Epoch 65/300\n",
            "1200/1200 [==============================] - 0s 144us/sample - loss: 2.2996 - accuracy: 0.1192 - val_loss: 2.2984 - val_accuracy: 0.1433\n",
            "Epoch 66/300\n",
            "1200/1200 [==============================] - 0s 144us/sample - loss: 2.2994 - accuracy: 0.1192 - val_loss: 2.2985 - val_accuracy: 0.1433\n",
            "Epoch 67/300\n",
            "1200/1200 [==============================] - 0s 142us/sample - loss: 2.2990 - accuracy: 0.1192 - val_loss: 2.2994 - val_accuracy: 0.1433\n",
            "Epoch 68/300\n",
            "1200/1200 [==============================] - 0s 150us/sample - loss: 2.2986 - accuracy: 0.1192 - val_loss: 2.2979 - val_accuracy: 0.1433\n",
            "Epoch 69/300\n",
            "1200/1200 [==============================] - 0s 141us/sample - loss: 2.2974 - accuracy: 0.1192 - val_loss: 2.2955 - val_accuracy: 0.1433\n",
            "Epoch 70/300\n",
            "1200/1200 [==============================] - 0s 154us/sample - loss: 2.2956 - accuracy: 0.1192 - val_loss: 2.2915 - val_accuracy: 0.1433\n",
            "Epoch 71/300\n",
            "1200/1200 [==============================] - 0s 154us/sample - loss: 2.2912 - accuracy: 0.1192 - val_loss: 2.2868 - val_accuracy: 0.1433\n",
            "Epoch 72/300\n",
            "1200/1200 [==============================] - 0s 145us/sample - loss: 2.2840 - accuracy: 0.1192 - val_loss: 2.2808 - val_accuracy: 0.1433\n",
            "Epoch 73/300\n",
            "1200/1200 [==============================] - 0s 150us/sample - loss: 2.2720 - accuracy: 0.1192 - val_loss: 2.2613 - val_accuracy: 0.1433\n",
            "Epoch 74/300\n",
            "1200/1200 [==============================] - 0s 144us/sample - loss: 2.2500 - accuracy: 0.1825 - val_loss: 2.2373 - val_accuracy: 0.2433\n",
            "Epoch 75/300\n",
            "1200/1200 [==============================] - 0s 135us/sample - loss: 2.2223 - accuracy: 0.2092 - val_loss: 2.2029 - val_accuracy: 0.2300\n",
            "Epoch 76/300\n",
            "1200/1200 [==============================] - 0s 152us/sample - loss: 2.1855 - accuracy: 0.2142 - val_loss: 2.1753 - val_accuracy: 0.2300\n",
            "Epoch 77/300\n",
            "1200/1200 [==============================] - 0s 147us/sample - loss: 2.1545 - accuracy: 0.2117 - val_loss: 2.1261 - val_accuracy: 0.2233\n",
            "Epoch 78/300\n",
            "1200/1200 [==============================] - 0s 143us/sample - loss: 2.1218 - accuracy: 0.2042 - val_loss: 2.1031 - val_accuracy: 0.2300\n",
            "Epoch 79/300\n",
            "1200/1200 [==============================] - 0s 153us/sample - loss: 2.0782 - accuracy: 0.2100 - val_loss: 2.0490 - val_accuracy: 0.2300\n",
            "Epoch 80/300\n",
            "1200/1200 [==============================] - 0s 144us/sample - loss: 2.0423 - accuracy: 0.2117 - val_loss: 2.0409 - val_accuracy: 0.2267\n",
            "Epoch 81/300\n",
            "1200/1200 [==============================] - 0s 142us/sample - loss: 2.0082 - accuracy: 0.2133 - val_loss: 2.0188 - val_accuracy: 0.2300\n",
            "Epoch 82/300\n",
            "1200/1200 [==============================] - 0s 153us/sample - loss: 2.0021 - accuracy: 0.2100 - val_loss: 1.9858 - val_accuracy: 0.2267\n",
            "Epoch 83/300\n",
            "1200/1200 [==============================] - 0s 149us/sample - loss: 1.9959 - accuracy: 0.2083 - val_loss: 1.9944 - val_accuracy: 0.2267\n",
            "Epoch 84/300\n",
            "1200/1200 [==============================] - 0s 143us/sample - loss: 1.9666 - accuracy: 0.2117 - val_loss: 1.9702 - val_accuracy: 0.2267\n",
            "Epoch 85/300\n",
            "1200/1200 [==============================] - 0s 136us/sample - loss: 1.9596 - accuracy: 0.2075 - val_loss: 1.9559 - val_accuracy: 0.2267\n",
            "Epoch 86/300\n",
            "1200/1200 [==============================] - 0s 151us/sample - loss: 1.9533 - accuracy: 0.2117 - val_loss: 1.9789 - val_accuracy: 0.2233\n",
            "Epoch 87/300\n",
            "1200/1200 [==============================] - 0s 141us/sample - loss: 1.9444 - accuracy: 0.2100 - val_loss: 1.9863 - val_accuracy: 0.2367\n",
            "Epoch 88/300\n",
            "1200/1200 [==============================] - 0s 144us/sample - loss: 1.9287 - accuracy: 0.2167 - val_loss: 1.9862 - val_accuracy: 0.2367\n",
            "Epoch 89/300\n",
            "1200/1200 [==============================] - 0s 148us/sample - loss: 1.9438 - accuracy: 0.2133 - val_loss: 1.9824 - val_accuracy: 0.2367\n",
            "Epoch 90/300\n",
            "1200/1200 [==============================] - 0s 147us/sample - loss: 1.9217 - accuracy: 0.2108 - val_loss: 1.9779 - val_accuracy: 0.2267\n",
            "Epoch 91/300\n",
            "1200/1200 [==============================] - 0s 141us/sample - loss: 1.9282 - accuracy: 0.2092 - val_loss: 1.8929 - val_accuracy: 0.2433\n",
            "Epoch 92/300\n",
            "1200/1200 [==============================] - 0s 146us/sample - loss: 1.9373 - accuracy: 0.2125 - val_loss: 1.8835 - val_accuracy: 0.2433\n",
            "Epoch 93/300\n",
            "1200/1200 [==============================] - 0s 153us/sample - loss: 1.9195 - accuracy: 0.2067 - val_loss: 1.8980 - val_accuracy: 0.2433\n",
            "Epoch 94/300\n",
            "1200/1200 [==============================] - 0s 148us/sample - loss: 1.9031 - accuracy: 0.2158 - val_loss: 1.9308 - val_accuracy: 0.2400\n",
            "Epoch 95/300\n",
            "1200/1200 [==============================] - 0s 146us/sample - loss: 1.8969 - accuracy: 0.2158 - val_loss: 1.9286 - val_accuracy: 0.2400\n",
            "Epoch 96/300\n",
            "1200/1200 [==============================] - 0s 149us/sample - loss: 1.8961 - accuracy: 0.2142 - val_loss: 1.9159 - val_accuracy: 0.2400\n",
            "Epoch 97/300\n",
            "1200/1200 [==============================] - 0s 153us/sample - loss: 1.9110 - accuracy: 0.2150 - val_loss: 1.9454 - val_accuracy: 0.2400\n",
            "Epoch 98/300\n",
            "1200/1200 [==============================] - 0s 143us/sample - loss: 1.9018 - accuracy: 0.2150 - val_loss: 1.9400 - val_accuracy: 0.2400\n",
            "Epoch 99/300\n",
            "1200/1200 [==============================] - 0s 143us/sample - loss: 1.9013 - accuracy: 0.2075 - val_loss: 1.9364 - val_accuracy: 0.2300\n",
            "Epoch 100/300\n",
            "1200/1200 [==============================] - 0s 151us/sample - loss: 1.9111 - accuracy: 0.2100 - val_loss: 2.0033 - val_accuracy: 0.2367\n",
            "Epoch 101/300\n",
            "1200/1200 [==============================] - 0s 145us/sample - loss: 1.9621 - accuracy: 0.2092 - val_loss: 2.0070 - val_accuracy: 0.2367\n",
            "Epoch 102/300\n",
            "1200/1200 [==============================] - 0s 154us/sample - loss: 1.9565 - accuracy: 0.1967 - val_loss: 1.9955 - val_accuracy: 0.2267\n",
            "Epoch 103/300\n",
            "1200/1200 [==============================] - 0s 157us/sample - loss: 1.9536 - accuracy: 0.1975 - val_loss: 1.9856 - val_accuracy: 0.2267\n",
            "Epoch 104/300\n",
            "1200/1200 [==============================] - 0s 146us/sample - loss: 1.9543 - accuracy: 0.2050 - val_loss: 1.9073 - val_accuracy: 0.2400\n",
            "Epoch 105/300\n",
            "1200/1200 [==============================] - 0s 151us/sample - loss: 1.8923 - accuracy: 0.2058 - val_loss: 1.8999 - val_accuracy: 0.2267\n",
            "Epoch 106/300\n",
            "1200/1200 [==============================] - 0s 147us/sample - loss: 1.8903 - accuracy: 0.2158 - val_loss: 1.8988 - val_accuracy: 0.2267\n",
            "Epoch 107/300\n",
            "1200/1200 [==============================] - 0s 147us/sample - loss: 1.8887 - accuracy: 0.2167 - val_loss: 1.8995 - val_accuracy: 0.2400\n",
            "Epoch 108/300\n",
            "1200/1200 [==============================] - 0s 149us/sample - loss: 1.8884 - accuracy: 0.2158 - val_loss: 1.8988 - val_accuracy: 0.2400\n",
            "Epoch 109/300\n",
            "1200/1200 [==============================] - 0s 142us/sample - loss: 1.8866 - accuracy: 0.2108 - val_loss: 1.8982 - val_accuracy: 0.2300\n",
            "Epoch 110/300\n",
            "1200/1200 [==============================] - 0s 153us/sample - loss: 1.8859 - accuracy: 0.2067 - val_loss: 1.8946 - val_accuracy: 0.2333\n",
            "Epoch 111/300\n",
            "1200/1200 [==============================] - 0s 146us/sample - loss: 1.8902 - accuracy: 0.2050 - val_loss: 1.8683 - val_accuracy: 0.2333\n",
            "Epoch 112/300\n",
            "1200/1200 [==============================] - 0s 152us/sample - loss: 1.9041 - accuracy: 0.2167 - val_loss: 1.8892 - val_accuracy: 0.2433\n",
            "Epoch 113/300\n",
            "1200/1200 [==============================] - 0s 192us/sample - loss: 1.9188 - accuracy: 0.2017 - val_loss: 1.8795 - val_accuracy: 0.2467\n",
            "Epoch 114/300\n",
            "1200/1200 [==============================] - 0s 156us/sample - loss: 1.8836 - accuracy: 0.2100 - val_loss: 1.9370 - val_accuracy: 0.2300\n",
            "Epoch 115/300\n",
            "1200/1200 [==============================] - 0s 153us/sample - loss: 1.9017 - accuracy: 0.2183 - val_loss: 1.9284 - val_accuracy: 0.2433\n",
            "Epoch 116/300\n",
            "1200/1200 [==============================] - 0s 155us/sample - loss: 1.8812 - accuracy: 0.2042 - val_loss: 1.8798 - val_accuracy: 0.2467\n",
            "Epoch 117/300\n",
            "1200/1200 [==============================] - 0s 162us/sample - loss: 1.8853 - accuracy: 0.2058 - val_loss: 1.8513 - val_accuracy: 0.2433\n",
            "Epoch 118/300\n",
            "1200/1200 [==============================] - 0s 160us/sample - loss: 1.9028 - accuracy: 0.2125 - val_loss: 1.8692 - val_accuracy: 0.2433\n",
            "Epoch 119/300\n",
            "1200/1200 [==============================] - 0s 151us/sample - loss: 1.9496 - accuracy: 0.2000 - val_loss: 1.8810 - val_accuracy: 0.2300\n",
            "Epoch 120/300\n",
            "1200/1200 [==============================] - 0s 155us/sample - loss: 1.9013 - accuracy: 0.2067 - val_loss: 1.8903 - val_accuracy: 0.2333\n",
            "Epoch 121/300\n",
            "1200/1200 [==============================] - 0s 153us/sample - loss: 1.8994 - accuracy: 0.2142 - val_loss: 1.9219 - val_accuracy: 0.2467\n",
            "Epoch 122/300\n",
            "1200/1200 [==============================] - 0s 149us/sample - loss: 1.9039 - accuracy: 0.2142 - val_loss: 1.9135 - val_accuracy: 0.2467\n",
            "Epoch 123/300\n",
            "1200/1200 [==============================] - 0s 153us/sample - loss: 1.9003 - accuracy: 0.2167 - val_loss: 1.9222 - val_accuracy: 0.2467\n",
            "Epoch 124/300\n",
            "1200/1200 [==============================] - 0s 149us/sample - loss: 1.9053 - accuracy: 0.2083 - val_loss: 1.8990 - val_accuracy: 0.2333\n",
            "Epoch 125/300\n",
            "1200/1200 [==============================] - 0s 163us/sample - loss: 1.9014 - accuracy: 0.2025 - val_loss: 1.9711 - val_accuracy: 0.2333\n",
            "Epoch 126/300\n",
            "1200/1200 [==============================] - 0s 156us/sample - loss: 1.9404 - accuracy: 0.2075 - val_loss: 2.0250 - val_accuracy: 0.2367\n",
            "Epoch 127/300\n",
            "1200/1200 [==============================] - 0s 160us/sample - loss: 1.9495 - accuracy: 0.1992 - val_loss: 2.0006 - val_accuracy: 0.2267\n",
            "Epoch 128/300\n",
            "1200/1200 [==============================] - 0s 153us/sample - loss: 1.9305 - accuracy: 0.2100 - val_loss: 1.9943 - val_accuracy: 0.2367\n",
            "Epoch 129/300\n",
            "1200/1200 [==============================] - 0s 152us/sample - loss: 1.9224 - accuracy: 0.2083 - val_loss: 1.9021 - val_accuracy: 0.2467\n",
            "Epoch 130/300\n",
            "1200/1200 [==============================] - 0s 149us/sample - loss: 1.9093 - accuracy: 0.2150 - val_loss: 1.9016 - val_accuracy: 0.2400\n",
            "Epoch 131/300\n",
            "1200/1200 [==============================] - 0s 157us/sample - loss: 1.9074 - accuracy: 0.2150 - val_loss: 1.8984 - val_accuracy: 0.2400\n",
            "Epoch 132/300\n",
            "1200/1200 [==============================] - 0s 158us/sample - loss: 1.8958 - accuracy: 0.2150 - val_loss: 1.9134 - val_accuracy: 0.2467\n",
            "Epoch 133/300\n",
            "1200/1200 [==============================] - 0s 154us/sample - loss: 1.9118 - accuracy: 0.2117 - val_loss: 1.9865 - val_accuracy: 0.2233\n",
            "Epoch 134/300\n",
            "1200/1200 [==============================] - 0s 151us/sample - loss: 1.9175 - accuracy: 0.2108 - val_loss: 1.9527 - val_accuracy: 0.2400\n",
            "Epoch 135/300\n",
            "1200/1200 [==============================] - 0s 149us/sample - loss: 1.9030 - accuracy: 0.2033 - val_loss: 1.9499 - val_accuracy: 0.2300\n",
            "Epoch 136/300\n",
            "1200/1200 [==============================] - 0s 160us/sample - loss: 1.9027 - accuracy: 0.2050 - val_loss: 1.9303 - val_accuracy: 0.2333\n",
            "Epoch 137/300\n",
            "1200/1200 [==============================] - 0s 154us/sample - loss: 1.9001 - accuracy: 0.2200 - val_loss: 1.9382 - val_accuracy: 0.2433\n",
            "Epoch 138/300\n",
            "1200/1200 [==============================] - 0s 152us/sample - loss: 1.9004 - accuracy: 0.2092 - val_loss: 1.9391 - val_accuracy: 0.2433\n",
            "Epoch 139/300\n",
            "1200/1200 [==============================] - 0s 145us/sample - loss: 1.8976 - accuracy: 0.2142 - val_loss: 1.9350 - val_accuracy: 0.2433\n",
            "Epoch 140/300\n",
            "1200/1200 [==============================] - 0s 162us/sample - loss: 1.8971 - accuracy: 0.2142 - val_loss: 1.9357 - val_accuracy: 0.2467\n",
            "Epoch 141/300\n",
            "1200/1200 [==============================] - 0s 152us/sample - loss: 1.8971 - accuracy: 0.2142 - val_loss: 1.9355 - val_accuracy: 0.2433\n",
            "Epoch 142/300\n",
            "1200/1200 [==============================] - 0s 162us/sample - loss: 1.8977 - accuracy: 0.2142 - val_loss: 1.9355 - val_accuracy: 0.2433\n",
            "Epoch 143/300\n",
            "1200/1200 [==============================] - 0s 157us/sample - loss: 1.8973 - accuracy: 0.2142 - val_loss: 1.9359 - val_accuracy: 0.2433\n",
            "Epoch 144/300\n",
            "1200/1200 [==============================] - 0s 149us/sample - loss: 1.8972 - accuracy: 0.2133 - val_loss: 1.9381 - val_accuracy: 0.2300\n",
            "Epoch 145/300\n",
            "1200/1200 [==============================] - 0s 155us/sample - loss: 1.8973 - accuracy: 0.2142 - val_loss: 1.9369 - val_accuracy: 0.2300\n",
            "Epoch 146/300\n",
            "1200/1200 [==============================] - 0s 162us/sample - loss: 1.8967 - accuracy: 0.2108 - val_loss: 1.9364 - val_accuracy: 0.2433\n",
            "Epoch 147/300\n",
            "1200/1200 [==============================] - 0s 161us/sample - loss: 1.8967 - accuracy: 0.2142 - val_loss: 1.9370 - val_accuracy: 0.2433\n",
            "Epoch 148/300\n",
            "1200/1200 [==============================] - 0s 161us/sample - loss: 1.8967 - accuracy: 0.2083 - val_loss: 1.9332 - val_accuracy: 0.2300\n",
            "Epoch 149/300\n",
            "1200/1200 [==============================] - 0s 164us/sample - loss: 1.8966 - accuracy: 0.2075 - val_loss: 1.9312 - val_accuracy: 0.2500\n",
            "Epoch 150/300\n",
            "1200/1200 [==============================] - 0s 156us/sample - loss: 1.8963 - accuracy: 0.2042 - val_loss: 1.9325 - val_accuracy: 0.2300\n",
            "Epoch 151/300\n",
            "1200/1200 [==============================] - 0s 161us/sample - loss: 1.8964 - accuracy: 0.2083 - val_loss: 1.9362 - val_accuracy: 0.2433\n",
            "Epoch 152/300\n",
            "1200/1200 [==============================] - 0s 161us/sample - loss: 1.8961 - accuracy: 0.2100 - val_loss: 1.9369 - val_accuracy: 0.2300\n",
            "Epoch 153/300\n",
            "1200/1200 [==============================] - 0s 149us/sample - loss: 1.8963 - accuracy: 0.2108 - val_loss: 1.9358 - val_accuracy: 0.2433\n",
            "Epoch 154/300\n",
            "1200/1200 [==============================] - 0s 147us/sample - loss: 1.8961 - accuracy: 0.2092 - val_loss: 1.9365 - val_accuracy: 0.2300\n",
            "Epoch 155/300\n",
            "1200/1200 [==============================] - 0s 159us/sample - loss: 1.8960 - accuracy: 0.2100 - val_loss: 1.9359 - val_accuracy: 0.2433\n",
            "Epoch 156/300\n",
            "1200/1200 [==============================] - 0s 153us/sample - loss: 1.8961 - accuracy: 0.2083 - val_loss: 1.9359 - val_accuracy: 0.2300\n",
            "Epoch 157/300\n",
            "1200/1200 [==============================] - 0s 172us/sample - loss: 1.8964 - accuracy: 0.1958 - val_loss: 1.9369 - val_accuracy: 0.2433\n",
            "Epoch 158/300\n",
            "1200/1200 [==============================] - 0s 147us/sample - loss: 1.8963 - accuracy: 0.2142 - val_loss: 1.9358 - val_accuracy: 0.2433\n",
            "Epoch 159/300\n",
            "1200/1200 [==============================] - 0s 164us/sample - loss: 1.8962 - accuracy: 0.2100 - val_loss: 1.9372 - val_accuracy: 0.2433\n",
            "Epoch 160/300\n",
            "1200/1200 [==============================] - 0s 155us/sample - loss: 1.8964 - accuracy: 0.2100 - val_loss: 1.9356 - val_accuracy: 0.2300\n",
            "Epoch 161/300\n",
            "1200/1200 [==============================] - 0s 165us/sample - loss: 1.8961 - accuracy: 0.2133 - val_loss: 1.9355 - val_accuracy: 0.2433\n",
            "Epoch 162/300\n",
            "1200/1200 [==============================] - 0s 158us/sample - loss: 1.8960 - accuracy: 0.2067 - val_loss: 1.9363 - val_accuracy: 0.2300\n",
            "Epoch 163/300\n",
            "1200/1200 [==============================] - 0s 155us/sample - loss: 1.8962 - accuracy: 0.2125 - val_loss: 1.9366 - val_accuracy: 0.2433\n",
            "Epoch 164/300\n",
            "1200/1200 [==============================] - 0s 152us/sample - loss: 1.8959 - accuracy: 0.2058 - val_loss: 1.9354 - val_accuracy: 0.2300\n",
            "Epoch 165/300\n",
            "1200/1200 [==============================] - 0s 161us/sample - loss: 1.8962 - accuracy: 0.2108 - val_loss: 1.9351 - val_accuracy: 0.2433\n",
            "Epoch 166/300\n",
            "1200/1200 [==============================] - 0s 156us/sample - loss: 1.8958 - accuracy: 0.2075 - val_loss: 1.9378 - val_accuracy: 0.2300\n",
            "Epoch 167/300\n",
            "1200/1200 [==============================] - 0s 165us/sample - loss: 1.8959 - accuracy: 0.2108 - val_loss: 1.9363 - val_accuracy: 0.2433\n",
            "Epoch 168/300\n",
            "1200/1200 [==============================] - 0s 135us/sample - loss: 1.8956 - accuracy: 0.2083 - val_loss: 1.9361 - val_accuracy: 0.2433\n",
            "Epoch 169/300\n",
            "1200/1200 [==============================] - 0s 147us/sample - loss: 1.8960 - accuracy: 0.2100 - val_loss: 1.9358 - val_accuracy: 0.2433\n",
            "Epoch 170/300\n",
            "1200/1200 [==============================] - 0s 148us/sample - loss: 1.8958 - accuracy: 0.1900 - val_loss: 1.9349 - val_accuracy: 0.2300\n",
            "Epoch 171/300\n",
            "1200/1200 [==============================] - 0s 139us/sample - loss: 1.8958 - accuracy: 0.2008 - val_loss: 1.9352 - val_accuracy: 0.2300\n",
            "Epoch 172/300\n",
            "1200/1200 [==============================] - 0s 149us/sample - loss: 1.8959 - accuracy: 0.2067 - val_loss: 1.9353 - val_accuracy: 0.2433\n",
            "Epoch 173/300\n",
            "1200/1200 [==============================] - 0s 142us/sample - loss: 1.8938 - accuracy: 0.2083 - val_loss: 1.9358 - val_accuracy: 0.2300\n",
            "Epoch 174/300\n",
            "1200/1200 [==============================] - 0s 155us/sample - loss: 1.8936 - accuracy: 0.2142 - val_loss: 1.9365 - val_accuracy: 0.2300\n",
            "Epoch 175/300\n",
            "1200/1200 [==============================] - 0s 151us/sample - loss: 1.8937 - accuracy: 0.2142 - val_loss: 1.9352 - val_accuracy: 0.2433\n",
            "Epoch 176/300\n",
            "1200/1200 [==============================] - 0s 141us/sample - loss: 1.8938 - accuracy: 0.1975 - val_loss: 1.9353 - val_accuracy: 0.2433\n",
            "Epoch 177/300\n",
            "1200/1200 [==============================] - 0s 145us/sample - loss: 1.8937 - accuracy: 0.2083 - val_loss: 1.9374 - val_accuracy: 0.2300\n",
            "Epoch 178/300\n",
            "1200/1200 [==============================] - 0s 148us/sample - loss: 1.8936 - accuracy: 0.2100 - val_loss: 1.9371 - val_accuracy: 0.2433\n",
            "Epoch 179/300\n",
            "1200/1200 [==============================] - 0s 157us/sample - loss: 1.8937 - accuracy: 0.2142 - val_loss: 1.9367 - val_accuracy: 0.2433\n",
            "Epoch 180/300\n",
            "1200/1200 [==============================] - 0s 148us/sample - loss: 1.8935 - accuracy: 0.2142 - val_loss: 1.9346 - val_accuracy: 0.2433\n",
            "Epoch 181/300\n",
            "1200/1200 [==============================] - 0s 157us/sample - loss: 1.8938 - accuracy: 0.2008 - val_loss: 1.9360 - val_accuracy: 0.2300\n",
            "Epoch 182/300\n",
            "1200/1200 [==============================] - 0s 157us/sample - loss: 1.8935 - accuracy: 0.2142 - val_loss: 1.9372 - val_accuracy: 0.2300\n",
            "Epoch 183/300\n",
            "1200/1200 [==============================] - 0s 144us/sample - loss: 1.8937 - accuracy: 0.2017 - val_loss: 1.9371 - val_accuracy: 0.2433\n",
            "Epoch 184/300\n",
            "1200/1200 [==============================] - 0s 155us/sample - loss: 1.8939 - accuracy: 0.2142 - val_loss: 1.9368 - val_accuracy: 0.2433\n",
            "Epoch 185/300\n",
            "1200/1200 [==============================] - 0s 141us/sample - loss: 1.8935 - accuracy: 0.2058 - val_loss: 1.9372 - val_accuracy: 0.2300\n",
            "Epoch 186/300\n",
            "1200/1200 [==============================] - 0s 154us/sample - loss: 1.8936 - accuracy: 0.2092 - val_loss: 1.9375 - val_accuracy: 0.2433\n",
            "Epoch 187/300\n",
            "1200/1200 [==============================] - 0s 166us/sample - loss: 1.8937 - accuracy: 0.2142 - val_loss: 1.9371 - val_accuracy: 0.2433\n",
            "Epoch 188/300\n",
            "1200/1200 [==============================] - 0s 153us/sample - loss: 1.8939 - accuracy: 0.2075 - val_loss: 1.9367 - val_accuracy: 0.2300\n",
            "Epoch 189/300\n",
            "1200/1200 [==============================] - 0s 152us/sample - loss: 1.8937 - accuracy: 0.2125 - val_loss: 1.9373 - val_accuracy: 0.2433\n",
            "Epoch 190/300\n",
            "1200/1200 [==============================] - 0s 147us/sample - loss: 1.8937 - accuracy: 0.2142 - val_loss: 1.9378 - val_accuracy: 0.2433\n",
            "Epoch 191/300\n",
            "1200/1200 [==============================] - 0s 143us/sample - loss: 1.8937 - accuracy: 0.1967 - val_loss: 1.9385 - val_accuracy: 0.2433\n",
            "Epoch 192/300\n",
            "1200/1200 [==============================] - 0s 149us/sample - loss: 1.8935 - accuracy: 0.2142 - val_loss: 1.9371 - val_accuracy: 0.2433\n",
            "Epoch 193/300\n",
            "1200/1200 [==============================] - 0s 138us/sample - loss: 1.8934 - accuracy: 0.2067 - val_loss: 1.9371 - val_accuracy: 0.2433\n",
            "Epoch 194/300\n",
            "1200/1200 [==============================] - 0s 142us/sample - loss: 1.8936 - accuracy: 0.2142 - val_loss: 1.9375 - val_accuracy: 0.2433\n",
            "Epoch 195/300\n",
            "1200/1200 [==============================] - 0s 144us/sample - loss: 1.8933 - accuracy: 0.2133 - val_loss: 1.9375 - val_accuracy: 0.2300\n",
            "Epoch 196/300\n",
            "1200/1200 [==============================] - 0s 145us/sample - loss: 1.8936 - accuracy: 0.2017 - val_loss: 1.9375 - val_accuracy: 0.2300\n",
            "Epoch 197/300\n",
            "1200/1200 [==============================] - 0s 139us/sample - loss: 1.8936 - accuracy: 0.2058 - val_loss: 1.9369 - val_accuracy: 0.2433\n",
            "Epoch 198/300\n",
            "1200/1200 [==============================] - 0s 153us/sample - loss: 1.8936 - accuracy: 0.2017 - val_loss: 1.9382 - val_accuracy: 0.2300\n",
            "Epoch 199/300\n",
            "1200/1200 [==============================] - 0s 146us/sample - loss: 1.8934 - accuracy: 0.2142 - val_loss: 1.9372 - val_accuracy: 0.2300\n",
            "Epoch 200/300\n",
            "1200/1200 [==============================] - 0s 153us/sample - loss: 1.8937 - accuracy: 0.2100 - val_loss: 1.9367 - val_accuracy: 0.2433\n",
            "Epoch 201/300\n",
            "1200/1200 [==============================] - 0s 137us/sample - loss: 1.8939 - accuracy: 0.2008 - val_loss: 1.9388 - val_accuracy: 0.2300\n",
            "Epoch 202/300\n",
            "1200/1200 [==============================] - 0s 144us/sample - loss: 1.8936 - accuracy: 0.2042 - val_loss: 1.9372 - val_accuracy: 0.2433\n",
            "Epoch 203/300\n",
            "1200/1200 [==============================] - 0s 159us/sample - loss: 1.8934 - accuracy: 0.2050 - val_loss: 1.9375 - val_accuracy: 0.2300\n",
            "Epoch 204/300\n",
            "1200/1200 [==============================] - 0s 153us/sample - loss: 1.8935 - accuracy: 0.2133 - val_loss: 1.9387 - val_accuracy: 0.2433\n",
            "Epoch 205/300\n",
            "1200/1200 [==============================] - 0s 147us/sample - loss: 1.8931 - accuracy: 0.2083 - val_loss: 1.9385 - val_accuracy: 0.2433\n",
            "Epoch 206/300\n",
            "1200/1200 [==============================] - 0s 144us/sample - loss: 1.8931 - accuracy: 0.2142 - val_loss: 1.9377 - val_accuracy: 0.2433\n",
            "Epoch 207/300\n",
            "1200/1200 [==============================] - 0s 135us/sample - loss: 1.8935 - accuracy: 0.2017 - val_loss: 1.9370 - val_accuracy: 0.2433\n",
            "Epoch 208/300\n",
            "1200/1200 [==============================] - 0s 147us/sample - loss: 1.8933 - accuracy: 0.2133 - val_loss: 1.9374 - val_accuracy: 0.2300\n",
            "Epoch 209/300\n",
            "1200/1200 [==============================] - 0s 142us/sample - loss: 1.8935 - accuracy: 0.2142 - val_loss: 1.9374 - val_accuracy: 0.2300\n",
            "Epoch 210/300\n",
            "1200/1200 [==============================] - 0s 151us/sample - loss: 1.8935 - accuracy: 0.2142 - val_loss: 1.9375 - val_accuracy: 0.2433\n",
            "Epoch 211/300\n",
            "1200/1200 [==============================] - 0s 159us/sample - loss: 1.8939 - accuracy: 0.2142 - val_loss: 1.9365 - val_accuracy: 0.2433\n",
            "Epoch 212/300\n",
            "1200/1200 [==============================] - 0s 153us/sample - loss: 1.8933 - accuracy: 0.2142 - val_loss: 1.9369 - val_accuracy: 0.2433\n",
            "Epoch 213/300\n",
            "1200/1200 [==============================] - 0s 141us/sample - loss: 1.8936 - accuracy: 0.2050 - val_loss: 1.9378 - val_accuracy: 0.2300\n",
            "Epoch 214/300\n",
            "1200/1200 [==============================] - 0s 146us/sample - loss: 1.8934 - accuracy: 0.2117 - val_loss: 1.9363 - val_accuracy: 0.2433\n",
            "Epoch 215/300\n",
            "1200/1200 [==============================] - 0s 150us/sample - loss: 1.8938 - accuracy: 0.1917 - val_loss: 1.9267 - val_accuracy: 0.2467\n",
            "Epoch 216/300\n",
            "1200/1200 [==============================] - 0s 145us/sample - loss: 1.8953 - accuracy: 0.2050 - val_loss: 1.9255 - val_accuracy: 0.2467\n",
            "Epoch 217/300\n",
            "1200/1200 [==============================] - 0s 152us/sample - loss: 1.8991 - accuracy: 0.2092 - val_loss: 1.8848 - val_accuracy: 0.2467\n",
            "Epoch 218/300\n",
            "1200/1200 [==============================] - 0s 145us/sample - loss: 1.8932 - accuracy: 0.2175 - val_loss: 1.8752 - val_accuracy: 0.2467\n",
            "Epoch 219/300\n",
            "1200/1200 [==============================] - 0s 144us/sample - loss: 1.8906 - accuracy: 0.2175 - val_loss: 1.8865 - val_accuracy: 0.2400\n",
            "Epoch 220/300\n",
            "1200/1200 [==============================] - 0s 148us/sample - loss: 1.8832 - accuracy: 0.2108 - val_loss: 1.8869 - val_accuracy: 0.2333\n",
            "Epoch 221/300\n",
            "1200/1200 [==============================] - 0s 149us/sample - loss: 1.8863 - accuracy: 0.2158 - val_loss: 1.9014 - val_accuracy: 0.2300\n",
            "Epoch 222/300\n",
            "1200/1200 [==============================] - 0s 145us/sample - loss: 1.8814 - accuracy: 0.2075 - val_loss: 1.8706 - val_accuracy: 0.2333\n",
            "Epoch 223/300\n",
            "1200/1200 [==============================] - 0s 147us/sample - loss: 1.8740 - accuracy: 0.2167 - val_loss: 1.8869 - val_accuracy: 0.2433\n",
            "Epoch 224/300\n",
            "1200/1200 [==============================] - 0s 142us/sample - loss: 1.8790 - accuracy: 0.2158 - val_loss: 1.9079 - val_accuracy: 0.2433\n",
            "Epoch 225/300\n",
            "1200/1200 [==============================] - 0s 166us/sample - loss: 1.8972 - accuracy: 0.2133 - val_loss: 1.9328 - val_accuracy: 0.2267\n",
            "Epoch 226/300\n",
            "1200/1200 [==============================] - 0s 149us/sample - loss: 1.8963 - accuracy: 0.2142 - val_loss: 1.9341 - val_accuracy: 0.2233\n",
            "Epoch 227/300\n",
            "1200/1200 [==============================] - 0s 149us/sample - loss: 1.8960 - accuracy: 0.2117 - val_loss: 1.9324 - val_accuracy: 0.2367\n",
            "Epoch 228/300\n",
            "1200/1200 [==============================] - 0s 150us/sample - loss: 1.8959 - accuracy: 0.2067 - val_loss: 1.9284 - val_accuracy: 0.2233\n",
            "Epoch 229/300\n",
            "1200/1200 [==============================] - 0s 147us/sample - loss: 1.9000 - accuracy: 0.2133 - val_loss: 1.9415 - val_accuracy: 0.2367\n",
            "Epoch 230/300\n",
            "1200/1200 [==============================] - 0s 144us/sample - loss: 1.8905 - accuracy: 0.2100 - val_loss: 1.8739 - val_accuracy: 0.2333\n",
            "Epoch 231/300\n",
            "1200/1200 [==============================] - 0s 142us/sample - loss: 1.8812 - accuracy: 0.2108 - val_loss: 1.8405 - val_accuracy: 0.2467\n",
            "Epoch 232/300\n",
            "1200/1200 [==============================] - 0s 144us/sample - loss: 1.8744 - accuracy: 0.2083 - val_loss: 1.8541 - val_accuracy: 0.2467\n",
            "Epoch 233/300\n",
            "1200/1200 [==============================] - 0s 139us/sample - loss: 1.8926 - accuracy: 0.2083 - val_loss: 1.9261 - val_accuracy: 0.2367\n",
            "Epoch 234/300\n",
            "1200/1200 [==============================] - 0s 144us/sample - loss: 1.8831 - accuracy: 0.2100 - val_loss: 1.8780 - val_accuracy: 0.2333\n",
            "Epoch 235/300\n",
            "1200/1200 [==============================] - 0s 145us/sample - loss: 1.9044 - accuracy: 0.2050 - val_loss: 1.8513 - val_accuracy: 0.2433\n",
            "Epoch 236/300\n",
            "1200/1200 [==============================] - 0s 148us/sample - loss: 1.9051 - accuracy: 0.2083 - val_loss: 1.8739 - val_accuracy: 0.2400\n",
            "Epoch 237/300\n",
            "1200/1200 [==============================] - 0s 150us/sample - loss: 2.0177 - accuracy: 0.2067 - val_loss: 2.0052 - val_accuracy: 0.2267\n",
            "Epoch 238/300\n",
            "1200/1200 [==============================] - 0s 147us/sample - loss: 1.9513 - accuracy: 0.2058 - val_loss: 1.8570 - val_accuracy: 0.2433\n",
            "Epoch 239/300\n",
            "1200/1200 [==============================] - 0s 145us/sample - loss: 1.9021 - accuracy: 0.2100 - val_loss: 1.8551 - val_accuracy: 0.2267\n",
            "Epoch 240/300\n",
            "1200/1200 [==============================] - 0s 144us/sample - loss: 1.8819 - accuracy: 0.2083 - val_loss: 1.8478 - val_accuracy: 0.2300\n",
            "Epoch 241/300\n",
            "1200/1200 [==============================] - 0s 159us/sample - loss: 1.8765 - accuracy: 0.2150 - val_loss: 1.8405 - val_accuracy: 0.2300\n",
            "Epoch 242/300\n",
            "1200/1200 [==============================] - 0s 153us/sample - loss: 1.8674 - accuracy: 0.2075 - val_loss: 1.8766 - val_accuracy: 0.2267\n",
            "Epoch 243/300\n",
            "1200/1200 [==============================] - 0s 146us/sample - loss: 1.8700 - accuracy: 0.2058 - val_loss: 1.8396 - val_accuracy: 0.2300\n",
            "Epoch 244/300\n",
            "1200/1200 [==============================] - 0s 154us/sample - loss: 1.8693 - accuracy: 0.2142 - val_loss: 1.8552 - val_accuracy: 0.2300\n",
            "Epoch 245/300\n",
            "1200/1200 [==============================] - 0s 161us/sample - loss: 1.8636 - accuracy: 0.2142 - val_loss: 1.8728 - val_accuracy: 0.2267\n",
            "Epoch 246/300\n",
            "1200/1200 [==============================] - 0s 152us/sample - loss: 1.8617 - accuracy: 0.2067 - val_loss: 1.8722 - val_accuracy: 0.2267\n",
            "Epoch 247/300\n",
            "1200/1200 [==============================] - 0s 150us/sample - loss: 1.8679 - accuracy: 0.2142 - val_loss: 1.8704 - val_accuracy: 0.2267\n",
            "Epoch 248/300\n",
            "1200/1200 [==============================] - 0s 146us/sample - loss: 1.8606 - accuracy: 0.2158 - val_loss: 1.8288 - val_accuracy: 0.2300\n",
            "Epoch 249/300\n",
            "1200/1200 [==============================] - 0s 154us/sample - loss: 1.8607 - accuracy: 0.2158 - val_loss: 1.8348 - val_accuracy: 0.2300\n",
            "Epoch 250/300\n",
            "1200/1200 [==============================] - 0s 161us/sample - loss: 1.8648 - accuracy: 0.2133 - val_loss: 1.8344 - val_accuracy: 0.2400\n",
            "Epoch 251/300\n",
            "1200/1200 [==============================] - 0s 145us/sample - loss: 1.8602 - accuracy: 0.2117 - val_loss: 1.8339 - val_accuracy: 0.2300\n",
            "Epoch 252/300\n",
            "1200/1200 [==============================] - 0s 148us/sample - loss: 1.8594 - accuracy: 0.2150 - val_loss: 1.8351 - val_accuracy: 0.2400\n",
            "Epoch 253/300\n",
            "1200/1200 [==============================] - 0s 152us/sample - loss: 1.8592 - accuracy: 0.2100 - val_loss: 1.8342 - val_accuracy: 0.2300\n",
            "Epoch 254/300\n",
            "1200/1200 [==============================] - 0s 148us/sample - loss: 1.8603 - accuracy: 0.2108 - val_loss: 1.8320 - val_accuracy: 0.2400\n",
            "Epoch 255/300\n",
            "1200/1200 [==============================] - 0s 148us/sample - loss: 1.8606 - accuracy: 0.2092 - val_loss: 1.8330 - val_accuracy: 0.2400\n",
            "Epoch 256/300\n",
            "1200/1200 [==============================] - 0s 150us/sample - loss: 1.8602 - accuracy: 0.2150 - val_loss: 1.8329 - val_accuracy: 0.2400\n",
            "Epoch 257/300\n",
            "1200/1200 [==============================] - 0s 156us/sample - loss: 1.8605 - accuracy: 0.2150 - val_loss: 1.8333 - val_accuracy: 0.2400\n",
            "Epoch 258/300\n",
            "1200/1200 [==============================] - 0s 152us/sample - loss: 1.8602 - accuracy: 0.2150 - val_loss: 1.8330 - val_accuracy: 0.2433\n",
            "Epoch 259/300\n",
            "1200/1200 [==============================] - 0s 142us/sample - loss: 1.8597 - accuracy: 0.2150 - val_loss: 1.8322 - val_accuracy: 0.2400\n",
            "Epoch 260/300\n",
            "1200/1200 [==============================] - 0s 146us/sample - loss: 1.8597 - accuracy: 0.2150 - val_loss: 1.8320 - val_accuracy: 0.2400\n",
            "Epoch 261/300\n",
            "1200/1200 [==============================] - 0s 158us/sample - loss: 1.8600 - accuracy: 0.2150 - val_loss: 1.8344 - val_accuracy: 0.2400\n",
            "Epoch 262/300\n",
            "1200/1200 [==============================] - 0s 145us/sample - loss: 1.8597 - accuracy: 0.2100 - val_loss: 1.8360 - val_accuracy: 0.2300\n",
            "Epoch 263/300\n",
            "1200/1200 [==============================] - 0s 147us/sample - loss: 1.8594 - accuracy: 0.2125 - val_loss: 1.8478 - val_accuracy: 0.2367\n",
            "Epoch 264/300\n",
            "1200/1200 [==============================] - 0s 150us/sample - loss: 1.8622 - accuracy: 0.2125 - val_loss: 1.8233 - val_accuracy: 0.2400\n",
            "Epoch 265/300\n",
            "1200/1200 [==============================] - 0s 147us/sample - loss: 1.8827 - accuracy: 0.2083 - val_loss: 1.8281 - val_accuracy: 0.2400\n",
            "Epoch 266/300\n",
            "1200/1200 [==============================] - 0s 143us/sample - loss: 1.8599 - accuracy: 0.2167 - val_loss: 1.8570 - val_accuracy: 0.2367\n",
            "Epoch 267/300\n",
            "1200/1200 [==============================] - 0s 150us/sample - loss: 1.8582 - accuracy: 0.2075 - val_loss: 1.8619 - val_accuracy: 0.2367\n",
            "Epoch 268/300\n",
            "1200/1200 [==============================] - 0s 150us/sample - loss: 1.8551 - accuracy: 0.2158 - val_loss: 1.8587 - val_accuracy: 0.2367\n",
            "Epoch 269/300\n",
            "1200/1200 [==============================] - 0s 140us/sample - loss: 1.8503 - accuracy: 0.2108 - val_loss: 1.8561 - val_accuracy: 0.2367\n",
            "Epoch 270/300\n",
            "1200/1200 [==============================] - 0s 145us/sample - loss: 1.8529 - accuracy: 0.2167 - val_loss: 1.8433 - val_accuracy: 0.2400\n",
            "Epoch 271/300\n",
            "1200/1200 [==============================] - 0s 144us/sample - loss: 1.8533 - accuracy: 0.2158 - val_loss: 1.8430 - val_accuracy: 0.2400\n",
            "Epoch 272/300\n",
            "1200/1200 [==============================] - 0s 144us/sample - loss: 1.8593 - accuracy: 0.2117 - val_loss: 1.8615 - val_accuracy: 0.2300\n",
            "Epoch 273/300\n",
            "1200/1200 [==============================] - 0s 148us/sample - loss: 1.8555 - accuracy: 0.2117 - val_loss: 1.8564 - val_accuracy: 0.2400\n",
            "Epoch 274/300\n",
            "1200/1200 [==============================] - 0s 145us/sample - loss: 1.8581 - accuracy: 0.2150 - val_loss: 1.8597 - val_accuracy: 0.2367\n",
            "Epoch 275/300\n",
            "1200/1200 [==============================] - 0s 149us/sample - loss: 1.8784 - accuracy: 0.2133 - val_loss: 1.8538 - val_accuracy: 0.2333\n",
            "Epoch 276/300\n",
            "1200/1200 [==============================] - 0s 147us/sample - loss: 1.8766 - accuracy: 0.2150 - val_loss: 1.8526 - val_accuracy: 0.2333\n",
            "Epoch 277/300\n",
            "1200/1200 [==============================] - 0s 147us/sample - loss: 1.8649 - accuracy: 0.2050 - val_loss: 1.8549 - val_accuracy: 0.2367\n",
            "Epoch 278/300\n",
            "1200/1200 [==============================] - 0s 144us/sample - loss: 1.8680 - accuracy: 0.2167 - val_loss: 1.8555 - val_accuracy: 0.2333\n",
            "Epoch 279/300\n",
            "1200/1200 [==============================] - 0s 151us/sample - loss: 1.8831 - accuracy: 0.2158 - val_loss: 1.8701 - val_accuracy: 0.2300\n",
            "Epoch 280/300\n",
            "1200/1200 [==============================] - 0s 141us/sample - loss: 1.8585 - accuracy: 0.2108 - val_loss: 1.8485 - val_accuracy: 0.2433\n",
            "Epoch 281/300\n",
            "1200/1200 [==============================] - 0s 160us/sample - loss: 1.8626 - accuracy: 0.2108 - val_loss: 1.8658 - val_accuracy: 0.2300\n",
            "Epoch 282/300\n",
            "1200/1200 [==============================] - 0s 151us/sample - loss: 1.9623 - accuracy: 0.2000 - val_loss: 1.8564 - val_accuracy: 0.2367\n",
            "Epoch 283/300\n",
            "1200/1200 [==============================] - 0s 150us/sample - loss: 1.8877 - accuracy: 0.2150 - val_loss: 1.8483 - val_accuracy: 0.2300\n",
            "Epoch 284/300\n",
            "1200/1200 [==============================] - 0s 145us/sample - loss: 1.8646 - accuracy: 0.2158 - val_loss: 1.8420 - val_accuracy: 0.2300\n",
            "Epoch 285/300\n",
            "1200/1200 [==============================] - 0s 148us/sample - loss: 1.8592 - accuracy: 0.2150 - val_loss: 1.8343 - val_accuracy: 0.2300\n",
            "Epoch 286/300\n",
            "1200/1200 [==============================] - 0s 147us/sample - loss: 1.8561 - accuracy: 0.2158 - val_loss: 1.8322 - val_accuracy: 0.2300\n",
            "Epoch 287/300\n",
            "1200/1200 [==============================] - 0s 143us/sample - loss: 1.8646 - accuracy: 0.2042 - val_loss: 1.8192 - val_accuracy: 0.2300\n",
            "Epoch 288/300\n",
            "1200/1200 [==============================] - 0s 157us/sample - loss: 1.8529 - accuracy: 0.2125 - val_loss: 1.8257 - val_accuracy: 0.2333\n",
            "Epoch 289/300\n",
            "1200/1200 [==============================] - 0s 156us/sample - loss: 1.8491 - accuracy: 0.2150 - val_loss: 1.8196 - val_accuracy: 0.2467\n",
            "Epoch 290/300\n",
            "1200/1200 [==============================] - 0s 152us/sample - loss: 1.8469 - accuracy: 0.2133 - val_loss: 1.8145 - val_accuracy: 0.2333\n",
            "Epoch 291/300\n",
            "1200/1200 [==============================] - 0s 152us/sample - loss: 1.8456 - accuracy: 0.2150 - val_loss: 1.8184 - val_accuracy: 0.2333\n",
            "Epoch 292/300\n",
            "1200/1200 [==============================] - 0s 154us/sample - loss: 1.8411 - accuracy: 0.2158 - val_loss: 1.8177 - val_accuracy: 0.2433\n",
            "Epoch 293/300\n",
            "1200/1200 [==============================] - 0s 140us/sample - loss: 1.8416 - accuracy: 0.2058 - val_loss: 1.8182 - val_accuracy: 0.2333\n",
            "Epoch 294/300\n",
            "1200/1200 [==============================] - 0s 147us/sample - loss: 1.8377 - accuracy: 0.2142 - val_loss: 1.8167 - val_accuracy: 0.2433\n",
            "Epoch 295/300\n",
            "1200/1200 [==============================] - 0s 153us/sample - loss: 1.8376 - accuracy: 0.2175 - val_loss: 1.8154 - val_accuracy: 0.2433\n",
            "Epoch 296/300\n",
            "1200/1200 [==============================] - 0s 141us/sample - loss: 1.8375 - accuracy: 0.2108 - val_loss: 1.8159 - val_accuracy: 0.2333\n",
            "Epoch 297/300\n",
            "1200/1200 [==============================] - 0s 148us/sample - loss: 1.8368 - accuracy: 0.2058 - val_loss: 1.8119 - val_accuracy: 0.2333\n",
            "Epoch 298/300\n",
            "1200/1200 [==============================] - 0s 142us/sample - loss: 1.8374 - accuracy: 0.2142 - val_loss: 1.8111 - val_accuracy: 0.2433\n",
            "Epoch 299/300\n",
            "1200/1200 [==============================] - 0s 161us/sample - loss: 1.8394 - accuracy: 0.2167 - val_loss: 1.8156 - val_accuracy: 0.2433\n",
            "Epoch 300/300\n",
            "1200/1200 [==============================] - 0s 153us/sample - loss: 1.8416 - accuracy: 0.2117 - val_loss: 1.8115 - val_accuracy: 0.2333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7effcad722b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VmBIBooUH-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1fZyFIGUH-c",
        "colab_type": "text"
      },
      "source": [
        "## Experiment observations\n",
        "\n",
        "- What is the distribution of the gradients observed as we move from the output layer to the input layer for each experiment? \n",
        "\n",
        "- Might need to run for [Tensorboard](http://localhost:6006) to run:\n",
        "\n",
        "      pip install --upgrade grpcio\n",
        "\n",
        "- Look in [Tensorboard](http://localhost:6006) at distributions or histograms charts named `Layer_00_Input/kernel_0_grad`, `Layer_01_Hidden/kernel_0_grad`, etc. for different layers. You should see:\n",
        "    - Gradients are usually higher at the output layer and tend to decrease as you move backwards in the network.\n",
        "    - With sigmoid activations gradients are always low and rapidly decay from the output layer all the way to the input layer.\n",
        "    - Relu might still have some vanishing gradient when weights are <0.\n",
        "    - Leaky Relu would probably have constant gradients across layers.\n",
        "    \n",
        "\n",
        "- Recall that, in the backpropagation algorithm, the gradient of the loss function $L$ with respect to the weights at a certain layer $W_l$ is proportional to the derivatives and the weights of previous layers:\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial W_l} \\propto f'(z^{(l)})\\cdot W_l \\cdot f'(z^{(l+1)})\\cdot W_{l+1} \\cdot f'(z^{(l+2)})\\cdot W_{l+2}...$$\n",
        "\n",
        "where $f'$ is the derivative of the activation function and $z^{(l)}$ is the output at layer $l$.\n",
        "\n",
        "- Do you think the sigmoid longrun would reach levels comparable to Relu or Leaky Relu? At what computational cost?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KU8T3tlAUcic",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "## Tensorboard in Colab\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaw6jxz7UH-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir log\n",
        "\n",
        "except:\n",
        "  print (\"not in colab\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX3PCKVIUn1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}